摘要：由于word2vec、Glove等静态词向量表示方法存在无法完整表示文本语义等问题，且当前主流神经网络模型在做文本分类问题时，其预测效果往往依赖于具体问题，场景适应性差，泛化能力弱。针对上述问题，提出一种多基模型框架(Stacking-Bert)的中文短文本分类方法。模型采用BERT预训练语言模型进行文本字向量表示，输出文本的深度特征信息向量，并利用TextCNN、DPCNN、TextRNN、TextRCNN等神经网络模型构建异质多基分类器，通过Stacking集成学习获取文本向量的不同特征信息表达，以提高模型的泛化能力，最后利用支持向量机(supportvectormachine,SVM)作为元分类器模型进行训练和预测。与word2vec-CNN、word2vec-BiLSTM、BERT-TexCNN、BERT-DPCNN、BERT-RNN、BERT-RCNN等文本分类算法在网络公开的三个中文数据集上进行对比实验，结果表明，Stacking-Bert集成学习模型的准确率、精确率、召回率和F1均为最高，能有效提升中文短文本的分类性能。文本分类一直是自然语言处理领域的重要研究课题，传统机器学习算法文本特征表达能力较弱，需要进行特征工程提取，基于海量大数据支撑的深度学习算法面临着对具体问题的强依赖性。而中文短文本具有特征词汇较少，词意复杂和特征稀疏等特点，现有文本分类算法的预测效果往往依赖于具体问题，不同场景状态下算法适应能力较弱，引起了中外学者的广泛关注[1,2,3]。徐清越等[4]提出一种融合双维度卷积神经网络(two-dimensionalconvolutionalneuralnetworks,TD-CNN)和位置自注意力机制(positionalattentionmechanism,PO-ATT)的文本分类模型，提取文本向量的丰富语义特征，根据词语和字符两种不同嵌入级别的特征向量表达进行语义分类研判。随后，陈可嘉等[5]提出一种基于全局词向量表示(globalvectorsforwordrepresentation,Glove)和隐含狄利克雷分布(latentdirichletallocation,LDA)主题模型的文本表示改进方法，训练隐含主题信息和相应概率信息分布的主题向量，计算两者相似性作为输入。相比传统语义分类模型，上述方法在一定程度上提升了文本分类器的性能。沈雅婷等[6]提出一种基于自举汇聚法的文本分类多基模型框架(baggingfastText,B_f),以fastText为基础框架，运用集成学习思想，设置最优超参数组成多基模型，再通过投票机制确定文本最终类别，在大规模有监督文本分类任务中表现出了较好的普遍适用性。上述研究工作基于word2vec或Glove等静态词向量展开，在解决短文本分类问题时仍存在一定的局限性。近期，随着预训练语言模型的广泛应用，越来越多的学者开始将其用于文本的深层语义抽取，段丹丹等[7]提出一种基于预训练语言模型(bidirectionalencoderrepresentationsfromtransformer,BERT)的中文短文本分类模型，利用Transformer双向编码器在句子层面进行特征向量表示，在中文短文本分类任务中表现出了更好的模型性能。在此基础上，崔文武等[8]提出一种基于BERT模型的诉讼案件违法事实要素自动抽取方法，并引入循环神经网络对文本进行编码，提取上下文相关的语义信息。张翼翔等[9]提出一种基于BERT-BIGRU-ATT模型的短文本分类方法，利用BERT预训练语言模型提取文本字向量，并引入双向门控神经单元(bidirectionalgatedrecurrentunit,Bi-GRU)和注意力机制(attention,ATT),强化学习短文本的上下文语义特征。综合上述分析，现提出一种用于中文短文本分类的多基模型框架Stacking-Bert,通过集成多个异质基分类器实现文本向量的训练和预测。该模型采用BERT预训练语言模型对大量中文语料库进行预训练，得到融合词语本身和上下文语义信息的动态词向量表示，并将获得的短文本字向量与TextCNN、DPCNN、TextRNN、TextRCNN等神经网络模块相结合，运用Stacking集成学习思想，对多个异质基分类器设计一个元分类器模型进行训练和分类，以期解决现有文本分类算法适应各场景能力较弱，分类准确率较低的问题。1.1Stacking集成学习模型Stacking集成学习算法是一种通过构建一个元分类器模型来整合多个基分类模型的集成学习技术，通过将若干个具有学习能力较强和差异性较大的基分类器模型组合成一个强分类器，以此提升模型的泛化能力。Stacking集成通常包含多个不同的基模型和一个元模型。基分类器模型利用整个训练集进行训练，元分类器模型将多个异质基分类器模型的输出特征作为输入特征进行训练，模型框架结构如图1所示。图1Stacking集成学习算法框架图1Stacking集成学习算法框架下载原图Fig.1StackingintegratedlearningalgorithmframeworkStacking集成学习将训练好的基模型对整个训练集进行预测，将样本预测结果作为新训练集的特征值进行训练。在集成学习中，每个基分类器模型的学习能力和算法差异性是影响Stacking集成学习算法性能的关键因素，为了能够最大程度地发挥集成模型性能，基分类器模型在保持强学习能力的同时需要具备一定的异质性，从而提取不同的特征信息表达。最终得到的集成学习模型将具有兼顾基分类器和元分类器的算法学习能力，使得集成模型的预测准确率得到进一步提升。1.2BERT预训练语言模型BERT预训练语言模型是Devlin等[10]提出的一种动态词向量表示方法，采用多层双向的Transformer编码器对大量中文语料库进行预训练，在文本句子层面可以得到融合词语本身和上下文语义信息的动态词向量表示，模型结构如图2所示。BERT模型采用多层Transformer编码器设计，Transformer编码器是一个采用了多头自注意力机制(multi-headattention)的Seq2Seq序列模型，模型结构为Encoder-Decoder。BERT模型利用多层Transformer结构和多头自注意力机制对大量文语料库预训练，将中文文本输入映射为动态词向量表示，相比基于传统的静态词向量表示方法，能够更好地解决中文短文本中存在的同义词、近义词以及一词多义现象，从而实现更为完整的语义特征表达。图2BERT模型结构示意图图2BERT模型结构示意图下载原图Fig.2SchematicdiagramofBERTmodelstructureE1,E2,…,EN为文本序列输入向量；Trm为Transformer编码器结构组件；T1,T2,…,TN为BERT模型输出的动态词向量1.3基分类器模型由于中文短文本具有特征稀疏、维度不足等特征，在使用BERT模型进行文本字向量表示的基础上，采用当前主流的4种神经网络分类模型来构造Stacking集成学习的基分类器，主要包括TextCNN经典卷积神经网络模型、DPCNN新型卷积神经网络、RNN循环神经网络以及RCNN混合神经网络模型。(1)TextCNN文本卷积神经网络[11]是一种经典的文本分类算法，Kim等[12]首次将卷积神经网络应用到文本分类领域，采用多个不同大小的卷积核在句子层面对文本词汇进行卷积操作，能够有效提取短文本的词级特征信息。(2)DPCNN新型卷积神经网络[13]针对TextCNN模型不能学习文本的长距离依赖关系的不足，通过不断增加网络深度，从而有效地抽取文本的长距离依赖关系。(3)RNN循环神经网络[14]在每一个时间步长上输入文本序列中的一个词向量表示，计算当前时间步长上的隐藏状态，然后当前时间步长下的输出传递给下一个时间步长，结合下一个时间步长的词向量一起作为RNN网络单元的输入，再计算下一个时间步长上的RNN隐藏状态，从而学习文本序列的上下文依赖关系。(4)RCNN混合神经网络模型[15]结合了RNN和CNN两个网络模块用于文本分类，同时考虑每个词的词向量和上下文的依赖关系，共同构成词向量的最终嵌入表示。TextCNN、DPCNN、RNN和RCNN神经网络采用具有不同的网络结构设计进行文本向量的特征提取，TextCNN注重于文本词汇特征信息捕捉，DPCNN注重于文本的长距离关系抽取，RNN注重于学习文本序列的上下文依赖关系，RCNN结合RNN和CNN两个模块设计，充分考虑每个词的词向量和上下文的向量表示。针对不同的目标任务的关注点，该4种神经网络模块有着自身独特的算法优势，且具有不同的场景适应能力，在多项自然语言处理(naturallanguageprocessing,NLP)任务中均有着良好的表现。2基于Stacking-Bert的短文本分类2.1Stacking-Bert多基模型框架深度学习算法在文本分类领域得到了广泛应用，但其分类效果往往依赖于具体问题。集成学习通过综合多个异质基分类器来预测结果，具有更强的场景适应能力和更高的分类准确率。基于Stacking集成学习思想，提出一种Stacking-Bert多基模型框架的中文短文本分类算法，充分考虑多个基分类器模型之间的差异性和学习能力，对BERT模型进行网络结构微调，在BERT模型内部的Transfomer编码器后面嵌入TextCNN、DPCNN、RNN和RCNN神经网络模块实现网络层的融合，最终形成5种基模型分类器，分别为：BERT-Base、BERT-TextCNN、BERT-DPCNN、BERT-RNN和BERT-RCNN,其中，“-”表示把BERT预训练语言模型的最后一层Transformer结构的输出分别输入到对应的下游任务神经网络层中，BERT-Base表示BERT模型本身的原始输出，模型结构如图3所示。其中，BERT模型采用多层双向Transformer编码器对大量中文预料库进行训练，可以得到融合词语本身和上下文语义信息的动态词向量表示，在一定程度上可以解决短文本的特征稀疏和一词多义问题。卷积神经网络(CNN)可以有效捕获文本的词级结构信息，循环神经网络(RNN)可以学习文本的上下文依赖关系，是文本特征提取的经典神经网络结构。本文研究设计Stacking-Bert多基模型框架第一层基分类器选择BERT-Base、BERT-TextCNN、BERT-DPCNN、BERT-RNN和BERT-RCNN神经网络模块进行训练得到模型预测结果，第二层元分类器采用支持向量机实现输入向量从低维空间到高维空间的映射，用于对第1层基分类器模型学习结果的集成分类，充分考虑性能较好模型具有的优势和性能较差模型带来的偏差，从而提高模型的泛化能力和场景适应能力。图3Stacking-Bert多基模型框架图3Stacking-Bert多基模型框架下载原图Fig.3Stacking-Bertmulti-basemodelframework2.2算法描述基于Stacking-Bert多基模型框架的集成学习算法伪代码如下。导出到EXCEL算法1Stacking-Bert集成学习算法输入:训练集D={(x1,y1),(x2,y2),…,(xm,ym)};基分类器模型ζ1,ζ2,…,ζT;元分类器模型ζ。过程:1:fort=1,2,…,Tdo2:ht=ζt(D);3:endfor4:D′=∅;5:fori=1,2,…,mdo6:fort=1,2,…,Tdo7:zit=ht(xi);8:endfor9:D′=D′∪((zi1,zi2,…,ziT),yi);10:endfor11:h′=ζ(D′);输出:集成模型H(x)=h′(h1(x),h2(x),…,hT(x))。3实验结果与分析3.1数据集介绍为测试各模型的短文本分类效果，采用网络公开的三个中文数据集，分别包括搜狗新闻THUCNews_data,新浪微博simplifyweibo_moods,京东评论Jingdong_data。其中搜狗新闻数据集包含10种新闻类别，共计200000条。新浪微博数据集包含喜悦、愤怒、厌恶和低落4种情感类别，共计361744条。京东评论数据集为网上手机购物的正负评论，包含好评、中评、差评3种类别，共计3000条。选取的3类数据集可以测试模型分别在大规模数据样本下和小样本数据集下的性能表现。随机选取其中80%的数据样本作为训练集，10%作为验证集，剩余10%作为测试集。为了测试模型的泛化能力，各标签类别数据保持一定程度的不平衡性，三个中文数据集的概况如表1所示。表1数据集统计表导出到EXCELTable1Datasetstatisticstable数据集训练集测试集验证集类别搜狗新闻180000100001000010新浪微博28939636174361744京东评论240030030033.2对比实验采用当前主流的深度学习文本分类算法作为对比实验，包括word2vec-CNN、word2vec-BiLSTM、BERT-texCNN、BERT-DPCNN、BERT-RNN、BERT-RCNN等文本分类算法。(1)word2vec-CNN和word2vec-BiLSTM文本分类算法采用word2vec词向量表示方法，然后把词向量分别输入到CNN模型和BiLSTM模型中再次进行特征信息提取，最后通过softmax进行分类，是目前常用的文本分类算法。(2)BERT-TexCNN、BERT-DPCNN、BERT-RNN和BERT-RCNN文本分类算法采用BERT预训练语言模型进行字向量表示，分别以TexCNN、DPCNN、RNN和RCNN作为下游任务进行特征提取，相比word2vec词向量表示方法，提升了模型性能。3.3评价指标为了衡量本文所提模型的有效性，采用精确率(Precision)、召回率(Recall)和Micro-F1衡量模型的分类性能，其定义为Precission=TPTP+FP         (1)Recall=TPTP+FN         (2)Micro−F1=2Precision×RecallPrecision+Recall         (3)式中：Precision代表预测结果为正例的情况中预测正确的比例；Recall代表实际结果为正例的情况中预测正确的比例。Micro-F1同时考虑标签预测精确率和召回率，是两者的调和平均值，也是衡量不平衡数据集的重要指标。3.4参数设置基于Stacking-Bert集成学习的中文短文本分类方法，将中文短文本的长度处理为32,采用BERT模型进行动态词向量表示，并运用Stacking集成学习思想，利用TextCNN、DPCNN、RNN和RCNN等算法构造多个基分类器，模型训练过程中设置最大迭代次数epochs为20,一个批次训练样本为128,学习率为0.001。此外，为了保证模型的正常迭代，设置若连续输入超过1000个训练样本，模型效果还没有提升，则提前结束训练。模型参数详细设置如表2和表3所示。表2Stacking集成学习的特征参数导出到EXCELTable2FeatureparametersofStackingensemblelearning模型参数参数值文本长度32字向量维度300Channels队列数250Dropout随机丢弃概率0.5TextCNN、DPCNN滤波器大小(2,3,4)RNN隐藏层神经元个数128RNN堆叠层数2RCNN隐藏层神经元个数256RCNN堆叠层数1表3BERT模型参数设置导出到EXCELTable3BERTmodelparametersettings模型参数参数值Embedding词向量维度128隐藏层单元个数768多头自注意力机制的Head数64隐藏层数12激活函数gelu学习率0.00005隐藏层Dropout概率0.1使用Google提供的BERT-Base预训练语言模型，采用12层网络结构设计，隐藏层维数设置为768,采用Multi-HeadSelf-attention(head=12)。BERT模型训练参数设置如表3所示。3.5模型对比为了有效评估本文所提基于Stacking-Bert集成学习模型在中文短文本数据集上的分类性能，对比了当前主流的基于深度学习的文本分类算法，所有对比模型采用相同的模型参数设置和评价指标进行模型性能的衡量。为了防止实验结果的偶然性，对模型运行10次计算均值，得出的对比实验结果如表4所示。如表4所示，采用word2vec词向量表示方法的文本分类模型在三个数据集上的分类准确率最低，分别为0.87、0.68和0.64,这是由于word2vec静态词向量模型在解释文本一词多义、上下文依赖关系、序列结构特征等信息方面存在不足，而基于BERT模型的文本分类准确率整体得到了大幅度的提升，达到了0.94、0.88和0.85,说明BERT模型能有效地捕捉文本的深层信息特征。本文所提Stacking-Bert集成学习在BERT模型下游任务采用了不同的神经网络结构提取文本不同的信息特征表达，然后基于一个元学习器实现文本的分类预测，在搜狗新闻、新浪微博和京东评论三个数据集上都达到了最好的F1,分别为0.96、0.91和0.89,验证了Stacking-Bert集成学习对中文短文本分类的有效性。表4模型分类精确率导出到EXCELTable4ThePrecisionrateofmodelclassification模型评测指标搜狗新闻新浪微博京东评论word2vec-CNN召回率(Recall)0.870.680.62word2vec-BiLSTM0.860.640.60BERT-TextCNN0.940.890.85BERT-DPCNN0.950.890.85BERT-RNN0.950.860.83BERT-RCNN0.940.880.86Stacking-Bert0.960.910.89word2vec-CNN精确率(Precision)0.880.680.68word2vec-BiLSTM0.870.650.61BERT-TextCNN0.940.900.85BERT-DPCNN0.940.880.86BERT-RNN0.950.860.83BERT-RCNN0.950.890.85Stacking-Bert0.960.910.90word2vec-CNNF1(Micro-F1)0.870.680.64word2vec-BiLSTM0.870.640.60BERT-TextCNN0.940.890.85BERT-DPCNN0.940.880.86BERT-RNN0.950.860.83BERT-RCNN0.940.880.85Stacking-Bert0.960.910.89此外，实验结果表明，基于深度学习的文本分类效果在大规模搜狗新闻数据集上明显优于小样本京东评论数据集，表现出了深度学习算法对具体问题的强依赖性，而Stacking-bert集成模型在一定程度上减少了上述差距。4结论研究了一种基于Stacking-Bert集成学习的中文短文本分类方法。采用BERT预训练语言模型进行文本字向量表示，并将获得的短文本字向量与TextCNN、DPCNN、TextRNN、TextRCNN等神经网络模块相结合，提取不同的特征信息表达。然后运用Stacking集成学习思想，通过集成多个基分类器实现短文本的训练和预测，与word2vec-CNN、word2vec-BiLSTM、BERT-texCNN、BERT-DPCNN、BERT-RNN、BERT-RCNN等算法进行对比实验，该模型在精确率、召回率和整体F1等评价指标上均优于其他模型，对中文短文本的分类研究提供了一定的参考价值。BERT模型采用多层双向Transformer编码器对大量中文预料库进行训练，可以得到融合词语本身和上下文语义信息的动态词向量表示，在一定程度上可以解决短文本的特征稀疏和一次多义问题。TextCNN、DPCNN、TextRNN、TextRCNN基分类模型在保持算法强学习能力的同时具备一定的异质性，Stacking集成学习基于所有训练好的基模型的预测构造新的测试集，再对测试集进行预测，具有更好的泛化能力，能有效提升文本的分类精度，在特定领域的文本分类任务中具有非常高的应用价值。在下一步工作中，将针对大规模数据集探讨集成算法的复杂度问题，并针对大型数据集训练过程中造成的时间消耗和计算资源消耗，尝试使用分布式训练方法完成对基分类器模型的训练，在保证模型精度的同时提高模型训练效率。摘要：为了提高文本分类的准确率并解决文本图卷积神经网络对节点特征利用不足的问题，提出了一种新的文本分类模型，其内在融合了文本图卷积和Stacking集成学习方法的优点。该模型首先通过文本图卷积神经网络学习文档和词的全局表达以及文档的语法结构信息，再通过集成学习对文本图卷积提取的特征进行二次学习，以弥补文本图卷积节点特征利用不足的问题，提升单标签文本分类的准确率以及整个模型泛化能力。为了降低集成学习的时间消耗，移除了集成学习中的k折交叉验证机制，融合算法实现了文本图卷积和Stacking集成学习方法的关联。在R8、R52、MR、Ohsumed、20NG等数据集上的分类效果相对于传统的分类模型分别提升了1.5%、2.5%、11%、12%、7%以上，该方法在同领域的分类算法比较中表现优异。大数据时代，网络文本数据日益增长，数据量越来越庞大，科学管理和组织这些数据变得尤其重要，因此许多文本处理方法[1]应运而生。文本分类是自然语言处理中非常重要的研究领域之一，大量的应用使用了文本分类技术，如垃圾邮件检测、新闻过滤、计算表型、观点挖掘、情感分析和文档的组织[1,2]等。文本分类方法可分为传统方法和深度方法。传统文本分类方法主要采用的是机器学习方法，对文本的表示及分类进行研究。传统的文本特征提取方法如n-gram法，得到文本的表示不够充分，缺少文本的词序关系[2],这使得文本的表示受到限制，处理方式也不够灵活，且在分类方面只是采用单个分类器进行分类，分类精度不高。深度学习的文本表示方法，如利用卷积神经网络(CNN)[3]和基于BiLSTM[4]的循环神经网络(RNN)[5]学习局部连续的单词序列对文本进行表示学习，使文本的表示更加灵活，提升了文本分类的效果。然而这类文本表示方法无法获取句子的语法结构信息以及全局信息，使得分类效果受到限制。另外，CNN和RNN等深度学习模型受限于欧氏结构数据，对于文本这类原本就属于非欧氏结构的数据来说则需要做更多的处理。随着深度学习的进一步发展，图神经网络的研究得到越来越多的关注。研究人员发现，图神网络非常适合文本这类非欧氏结构数据的处理[6],如文本图卷积模型[7],能够在训练中自动学习单词和文档的嵌入；并且图神经网络能够整合文本的结构信息，提升文本的表征能力。然而在最终的分类方面，图神经网络模型并没有充分利用神经网络学习到的特征。为了解决以上问题并提升文本分类的效果，本文提出了新的文本分类模型TGCN-S(textGCN-Stacking),通过使用Stacking集成学习方法，对文本图卷积得到的特征进行拟合训练，解决文本图卷积特征利用不足的问题，提高了分类效果和模型的泛化能力；为了提高集成学习的速度，移除了集成学习中的交叉验证机制。该模型的有效性在R8、R52、MR、Ohsumed和20NG等数据集的实验上得到验证。综上所述，本文提出了新的文本分类模型TGCN-S,主要贡献和创新点概括如下：a)本文利用文本图卷积获取文本的全局信息和文本的结构信息，解决传统模型无法获取文本的结构信息的问题，提升文本的特征表达；b)优化Stacking集成学习模块，移除k折交叉验证，在保证分类效率的同时降低Stacking学习过程的时间消耗，将softmax分类器替换为Stacking集成学习分类器，有效地解决了文本图卷积特征利用不充分的问题，提升了整个模型的分类效果和泛化能力；c)融合文本图卷积和集成学习的优点，提出新的文本分类模型TGCN-S,提高文本分类的准确率。1相关工作1.1传统的文本分类传统的文本分类方法有很多，如支持向量机(SVM)[2]、K最近邻(KNN)和随机森林(RF)[1]等，这些文本分类方法主要聚焦于文本的表示以及相应算法的研究，例如词袋法和n-grams表示法。词袋法将文档划分为一个单词集合，并确定它们在文档中出现的频率；n-gram法[8]将文本中连续的n个词语作为一个对象，再将所有的对象放在一起形成一个集合。词袋法中，文本的最终表示结果与集合中单词顺序无关[2],这将导致句子语法特性以及单词间的相关性丢失，使得文本表示不够充分，无法得到文本全局信息；相比于词袋法，n-gram能够得到单词的相关性，但忽略了句子的句法特性，对文本的表示不够充分且缺乏灵活性，同样地，使得文本的全局信息丢失。1.2基于深度学习的文本分类目前，大多数的文本分类方法是基于深度学习的，其中具有代表性的如应用于语句分类的CNN[3]、基于双向长短期记忆BiLSTM[4]的RNN以及BERT模型[9]等。Kim[3]于2014年提出了基于CNN的语句分类，它将一维卷积应用在文本语句上，在分类准确度上取得了比较好的结果。Liu等人[5]通过将LSTM应用在文本分类中，以学习文本表示，保留文本更长的单词信息，提高了文本的表达能力。Devlin等人[9]提出了BERT模型，是一种预训练语言的文本表示模型，在大量文本语料中训练了一个通用的语言表示模型，能够捕获单词间更长的依赖。这些模型的出现很大程度上解决了传统分类方法文本表征不足的问题，但是没有捕获文本的结构信息和全局信息。CNN与RNN都主要是针对局部连续的单词序列，能够很好地捕获文本中的局部信息，但无法得到语料库中单词的全局共现信息以及文本的结构信息。并且以上模型都局限于欧氏结构数据的学习，对于非欧氏结构数据的处理则会显得捉襟见肘，例如文本数据，如果不进行特殊处理，很难捕获文本的结构信息。随着深度学习技术的发展，图神经网络的研究得到越来越多的关注。GNN不仅具有参数共享、降低计算量的优点，而且非常适合文本中单词之间非欧氏结构数据的处理，取得了机器学习领域的突破；GNN还能够提取多尺度的局部空间特征并抽象组合成高层特征，通过图嵌入，GNN能够学习图的节点、边以及子图的低维度向量表示[8],突破了一般机器学习需要依赖手工的网络结构设计问题，提高了学习的灵活性。Cai等人[8]证明了图神经网络能够很好地处理具有丰富关系的结构任务能够在图嵌入的过程中保留图的全局信息；Kipf等人[10]对图神经网络进行了简化，提出了一种图卷积神经网络模型GCN,该模型可以捕获高阶邻域特征，提升文本分类的准确率；Yao等人[7]将GCN运用到文本分类中并提出了TextGCN模型，对语料库构建大型的异构图，以句子和单词作为图中的节点，通过GCN学习单词和句子嵌入，获取文本中单词的全局信息以及整个文本的结构信息，最后得到文本的特征。1.3分类器目前，不管是传统的文本分类还是基于深度学习的文本分类方法，在提取文本的特征后，使用单一的分类器进行分类，如使用softmax得到每个类别的概率，并选择概率最大分类作为文本最终的分类。单一的分类器直接进行分类使得分类结果一次就确定下来，在出现分类失误的情况下，无法对分类结果进行修正调整。集成学习是由多个弱分类器组成的一个强分类器，可以作为一个整体的分类器用于分类，能够很好地解决单个分类器分类能力不足的问题[11]。集成学习可以分为Boosting算法、Bagging算法以及Stacking算法[12]三类。其中具有代表性的是Stacking算法，在灵活性和扩展性方面，Stacking算法比其他两个算法都要好[13,14],更具效率优势。Stacking模型能够灵活高效地对文本进行分类，然而，其分类效果依赖于传入Stacking模型的文本特征。基于以上问题，本文提出了一种融合文本图卷积和Stacking集成学习的文本分类方法TGCN-S,利用文本图卷积提取文本特征，通过集成学习弥补原图卷积特征利用不足的问题，提升文本分类的准确性以及模型的泛化能力。为了降低集成学习的拟合时间，移除了Stacking集成学习中的交叉验证机制，以提升集成学习部分的拟合速度。2TGCN-S算法本文通过融合文本图卷积和Stacking集成学习方法提出了一种新的文本分类算法TGCN-S,结合了文本图卷积和Stacking的优点，解决了文本图卷积特征利用不足的问题，提高了文本分类准确度和模型的泛化能力。为了降低集成学习部分的时间消耗，移除了Stacking集成学习中的交叉验证机制以提升集成学习的拟合速度，提高文本分类的效率。2.1TGCN-S模型结构本文提出的TGCN-S模型如图1所示，将模型分为特征提取和Stacking集成分类两部分。TGCN-S由TextGCN和Stacking两个部分连接而成，将TextGCN提取的特征作为Stacking集成学习的输入，并将TextGCN分类结果与Stacking第一层分类结果拼接作为Stacking第二层的输入，形成残差连接。这种跳跃式连接的方式提升了两个模型之间的关联，增强了Stacking第二层输入的特征表达。最终通过Stacking的第二部分进行分类，得到文本最后的分类结果。在图1中，文本异构图的黑点表示文档，白点表示单词，实线表示文档与单词的联系，虚线表示单词之间的联系，根据文本异构图计算得到的邻接矩阵作为TextGCN的输入。图1TGCN-S总体流程图1TGCN-S总体流程下载原图Fig.1TGCN-Soverallflowchart2.2特征提取本文主要使用TextGCN作为特征提取器，作为整个模型的第一部分。在对文本进行构图的过程中，将单词和文档作为图的节点，单词与文档之间的连接权值用词频逆文档频率(TF-IDF)表示，单词与单词之间的连接权值使用逐点互信息(PMI)表示。PMI的计算方式如下：PMI(i,j)=logP(i,j)P(i)×P(j),P(i,j)=N(i,j)N,P(i)=N(i)N(1)其中：N是滑动窗口总数；N(i,j)表示同时包含节点i、j的滑动窗口数；N(i)表示包含节点i的滑动窗口数；P(i,j)表示同时包含节点i、j的概率；P(i)表示滑动窗口包含节点i的概率。由此得到节点i、j之间边的权重Aij,定义如下：其中：w表示单词；doc表示一个文档。当PMI为正值时，表示语料库中单词的语义相关性较高；当PMI为负值时，表示语料库中单词的语义相关性很低或者没有。在构建异构图时，只在PMI为正值的节点对直接添加边；之后再将带权图输入到一个简单的两层GCN进行学习。在GCN第二层得到词文档嵌入，嵌入的维度与标签类别数大小相同。提取的特征Z可以用式(3)计算。最后将节点的嵌入送到softmax函数中，得到临时的分类输出Y,如式(4)所示。Z=A ˆReLU(A ˆXW0)W1(3)Y=softmax(Z)(4)其中：A ˆ=D ˆ−12A ˆD ˆ−12,而A ˆ=A+IN;A是n阶邻接矩阵；IN是n阶单位矩阵，n是顶点个数；D ˆ是A ˆ对应的度矩阵，其中D ˆij=∑jA ˆij;X是由n个节点的特征构成的特征矩阵；W0、W1分别是特定于第一层和第二层的可训练的权重矩阵；ReLU是层间的激活函数。2.3集成学习部分TGCN-S的第二个部分就是Stacking集成学习，传统的Stacking集成模型如图2所示。传统的Stacking集成学习模型(图2)对多个基分类器(Ck,(k=1,2,…,m))进行训练，然后将多个训练好的基分类器对训练集中的数据进行预测得到训练集的预测值Pi(i=1,2,…,m),再对测试集中的数据进行预测得到测试集对应的预测值pj(j=1,2,…,m),最后将多个基分类器得到的预测结果组合在一起拼接成新数据集，各个基分类器对同一个样本的预测结果组合在一起作为该样本的新特征，训练集得到的预测值组合在一起作为新的训练集特征(P1,P2,…,Pm),测试集得到的预测值组合在一起形成新的测试集特征(p1,p2,…,pm);然后将得到的两组特征集通过Stacking第二层融合分类器进行训练和预测，得到最后的分类。图2Stacking集成学习系统图2Stacking集成学习系统下载原图Fig.2Stackingintegratedlearningsystem一般地，TextGCN直接利用softmax对GCN中得到的特征进行分类，并以此作为最终输出，其对训练的特征并没有很好地利用。TGCN-S模型融合了Stacking集成分类以及TextGCN优点，在使用softmax对GCN中得到的特征进行分类的过程中，还利用Stacking集成学习中各基分类器对GCN学习到的特征进行二次拟合，最后进行融合分类，获得文本最终分类结果。与传统的Stacking集成学习不同，TGCN-S中Stacking集成学习部分包含基分类层和融合层。第一层基分类层由五个基分类器组成，第二层融合层除了直接使用各基分类器的分类结果和数据，还整合了TextGCN分类的输出结果和数据，即特征提取过程中的训练和预测结果Y(式(4)),形成跳跃式连接。这种跳跃式连接不仅增强了文本图卷积和Staking集成模型之间的联系，而且将TextGCN预测效果代入Stacking第二层，提升了融合层的分类效果。为了降低集成学习部分的时间消耗，去除Stacking的交叉验证机制以提高模型的拟合速度。模型的特征组合过程如图3所示，其中Ci(i=1,2,3,4,5)为基分类器，Tri为基分类器得到的训练结果，Tei(i=1,2,3,4,5)为基分类器的预测结果，train_set是由各个Tri组成的训练集，test_set是由各个Tei组成的测试集。图3新特征组合过程示意图图3新特征组合过程示意图下载原图Fig.3SchematicofthenewfeaturecombinationprocessStacking第一层是由多个基分类器组成，对于基分类器的选择，主要遵循的原则是“各个基分类器准而不同”,不同的基分类器之间要有所差异[12]。本文Stacking集成学习的基分类层采用了五种基分类器：支持向量机(SVM)、决策树(DT)、随机森林(RF)、K最近邻(KNN)以及高斯朴素贝叶斯(GaussianNB)。一般认为，这五种分类器具有基础性的作用，其他大多数分类方法基本上都是基于这五种分类器中的某一个或多个进行改进优化的。另外随着模型复杂性和模型数量的增加，模型整体训练的时间必然增加，模型训练拟合开销也会随之增加。基于以上考虑，TGCN-S模型Stacking第一层的基分类器以上述五种为主；第二层分类器在单个机器学习分类器预测的基础上采用投票法给出最终分类结果。3实验结果和分析3.1数据集主要使用R8、Ohsumed、MR、R52和20NG五个数据集对本文TGCN-S模型进行实验对比，分析TGCN-S的分类效果。a)R8数据集。该数据集分离自路透社语料库，只有八个类别，其中有5485个训练文档和2189个测试文档。b)Ohsumed数据集。它是由国家医学图书馆维护的重要的医学文献数目的数据库。提取其中只有单一分类的数据，构成本实验的训练测试用例，其中3357个文档用于训练，4043个文档用于测试，总共7400个数据。c)MR数据集。MR是一个电影评论数据集，每个评论只包含一句话，其中有5331篇正面评论，5331篇负面评论。d)R52数据集。它也是分离自路透社语料库，有52个类别，有6532个训练数据和2568个测试数据。e)20NG。它是一个含有20个类别的新闻组数据集，训练集有11314个文档，测试集有7532个文档。这些数据由于是文本数据，并不能直接用于模型的训练，需要对其进行预处理[7]。通过预处理，得到表1的统计信息，从中可以看到每个数据集的训练集和测试集的大小。表1各个数据集的统计信息导出到EXCELTab.1Statisticsforeachdataset数据集docstrainingtestwordsnodesclassesR87674548521897688153628R5291006532256888921799252Ohsumed740033574043141572155723MR10662710835541876429426220NG188461131475324275761603203.2对比模型实验数据1)CNN针对文本分类的卷积神经网络，由Kim[3]于2014年提出，通过在预训练的词向量之上训练的卷积神经网络进行句子级的分类任务。2)LSTM由Liu等人[5]于2016年提出的基于长短期记忆文本分类模型，通过使用最后一个隐藏状态作为整个文本的表示形式。3)Bi-LSTM双向长短期记忆文本分类模型，是LSTM的改版，以预训练的词嵌入作为Bi-LSTM[4]的输入。4)FastText由Joulin等人[15]于2017年提出的简单有效的文本分类模型，通过将单词n-gram嵌入的平均值作为文档的嵌入，再将得到的文档嵌入送入线性分类器进行分类。5)TextGCN由Yao等人[7]于2019年提出的基于图卷积的文本分类方法，该方法基于单词共现和文档单词关系为整个语料库构建大型异构文本图，再使用图卷积神经网络和softmax进行学习分类。通过本文模型与上述几个模型的实验对比得到不同模型在不同数据集上的准确率，结果如表2所示。表2数据集在各个模型上的预测准确率导出到EXCELTab.2Predictionaccuracyofdatasetsoneachmodel模型R8R52OhsumedMR20NGCNN0.94020.85370.43970.74980.7693LSTM0.93680.85540.41130.75060.6571Bi-LSTM0.96310.90540.49270.77680.7318FastText0.96130.92810.57700.75140.7967TextGCN0.97070.93560.68360.76740.8634TGCN-S-vote0.98580.96040.80900.88280.9302如表2所示，本文提出的TGCN-S在五个数据集上的测试精度都表现得最好，且有着不同程度的提升。针对R8数据集，TGCN-S的表现比其中最好的TextGCN高出了1.5个百分点，比其他文本分类算法的精度高出了至少2个百分点[7];对于R52数据集，本文模型比其他模型高出了2.5个百分点以上，相比于CNN模型，分类效果提高了13个百分点；在Ohsumed数据集，TGCN-S的表现比TextGCN模型的表现高出了12个百分点，比其他分类模型高出了20个百分点以上[7];对于MR数据集，TGCN-S模型在测试精度上比TextGCN模型高出了接近11个百分点[7],比其他模型都高出了接近14个百分点[7];在20NG这种较大数据集上，TGCN-S也比TextGCN模型高出7个百分点，比其他模型高出12个百分点以上。图4直观地展示了各个模型在所用数据集的预测结果。从图4可以看出，本文模型的分类效果都优于对比模型。图上的数据充分说明，Stacking集成学习能够对文本图卷积学习到的文本特征进行更高效的利用，能够在不同程度上提升分类效果。从表2的数据中可以发现，本文模型对不同的数据集的分类效果有着不同的提升，但对于Ohsumed和MR两个数据集的分类效果没有其他数据集的结果好，原因在于MR数据中存在多个极性评论，如“这部电影故事很丰富，但是太恐怖了”;同样地，在Ohsumed数据集中各种医学文献之间的描述是相互关联的，在描述某种病例时会提及与病例有关的药物和信息。图神经网络虽然能捕获文本全局信息，但是无法获取文本内的词序特征，以至于无法提取文本的详细特征，进而导致分类效果欠佳。即便如此，本文方法相对于其他单个分类器来说仍有非常大的提升。这也说明融合Stacking集成学习后的模型，通过投票机制能够有效地提高文本分类的效果，即便文本中存在多极性的描述，也能得到较高的准确率。这些实验数据也证明了本文模型的有效性，可以在很大程度上提升文本分类的准确率。图4模型预测结果直方图图4模型预测结果直方图下载原图Fig.4Predictionhistogramofmodels单一的准确率并不能很好地确定模型的质量，为此，本文采用对比各个模型的宏观F1(macro-F1)和微观F1(micro-F1)来评估模型的性能，它们是综合考虑了模型的查准率和查全率的计算结果，macro-F1与micro-F1的值越大，说明模型的质量越高、分类性能越好。文献[4]指出，TextGCN的模型分类效果和模型质量都优于CNN、LSTM、BiLSTM、FastText等，因此，本文主要对TextGCN与TGCN-S-vote模型的macro-F1与micro-F1值进行比较，以对比判断本文模型TCGN-S-vote的性能。各个数据集在两个模型的macro-F1与micro-F1值如表3所示。由表3可以看出，本文模型总体上的macro-F1与micro-F1的得分都比TextGCN模型的要高，说明本文模型相比于TextGCN模型的质量更高，模型的分类效果也更好。为了对比模型的收敛情况，将TextGCN与本文模型进行比较，通过每个epoch的准确率以及达到稳定时的状态来确定模型的收敛能力，实验结果用折线统计图来表示。图5分别画出了MR、R52、R8数据集在TextGCN和TGCN-S-vote模型的各个epoch的准确率。从图中可以看到，本文模型在各个数据集上的收敛速度都比TextGCN要快，都能更早地达到稳定状态。同时从分类准确率的角度来看，本文模型最终的分类准确率都比TextGCN要高。表3各数据集在TextGCN与TGCN-S-vote上的F1得分导出到EXCELTab.3F1scoreforeachdatasetonTextGCNandTGCN-S-vote评估标准模型R8R52OhsumedMR20NGmicro-F1TextGCN0.9690.5880.6740.8130.858TGCN-S-vote0.9770.8310.7810.8760.930macro-F1TextGCN0.9330.7110.6830.7580.853TGCN-S-vote0.9450.9600.7920.8790.9373.3去交叉验证的集成学习为了简化集成学习模块、提高整个模型的训练预测速度，去除了Stacking中所有基分类器的交叉验证机制，只通过随机打乱的方式对训练集和测试集进行处理，并在各个数据集上进行了对比实验。实验结果如表4所示。表4去交叉验证对比数据导出到EXCELTab.4Comparisondatawithremovedcross-checks方法R8R52OhsumedMR20NGKfoldt31.64225.5461.0227.73253.32nKfoldt11.2176.1033.265.26100.26KP0.98310.95380.83570.87580.9233nKP0.98580.96040.84290.88280.9334表4中，Kfoldt和KP分别表示使用k折交叉验证Stacking模型所花费的时间及分类准确率，nKfoldt和nKP分别表示未使用k折交叉验证Stacking部分的耗时及对应的分类准确率。从表4中可以发现，不使用k折交叉验证的时间消耗低于使用k折交叉验证的时间消耗，因为在Stacking部分少了k-1次的模型的拟合，所以时间有所减少。并且不使用k折交叉验证的分类准确率也表现出不低于使用k折交叉验证的分类准确率。这是因为，k折交叉验证原本用于数据集较少的情况，以提高模型的泛化能力，对于数据集较多的情况，进行交叉验证的效果收益甚微，还会影响模型的拟合速度，本实验的数据集就是如此。因此，本文模型去除了Stacking集成学习交叉验证机制，以降低模型的时间花费，提升模型训练预测速度的同时保持良好的分类准确率。图5训练周期与准确率的折线图图5训练周期与准确率的折线图下载原图Fig.5Linechartoftrainingcycleandaccuracy3.4集成学习融合层的对比实验为了分析Stacking模型中第二层融合分类器Vote对最终模型分类效果的影响，本实验通过选择九种常用机器学习方法作为Stacking第二层的融合分类法，并分别在R8、R52、Ohsumed、MR以及20NG这五个数据集进行对比实验。九种分类器如下：高斯贝叶斯分类器(GaussianNB)、线性回归(Linear-Regression)、逻辑回归(LogisticRegression)、决策树(DecisionTree)、LightGBM[16]、支持向量机(SVM)、AdaBoost[17]、Bagging[18]以及Voting投票法。实验结果如表5所示。从表5中可以看出，使用不同的分类方法作为融合层的分类器会有不同的分类效果。在这五个数据集中，除了在Ohsumed数据集上以LightGBM作为融合分类器的测试精度略大于投票法之外，其他数据集中投票法的测试精度都优于其他分类器。这体现了投票法的通用性，且投票法思想简单、易于实现。因此本文模型以投票法作为Stacking模型第二层的融合分类器。表5融合分类器在五个数据集上的表现导出到EXCELTab.5Performanceofeachfusedclassifieron5datasets融合分类器R8R52OhsumedMR20NGGaussianNB0.96890.95370.70570.87860.7538LinearRegression0.97830.95370.72890.75740.8192LogisticRegression0.96160.77360.38340.86730.4067DecisionTree0.97260.95690.76820.86320.8547LightGBM0.98360.09010.82170.85840.7738SVM0.96710.87630.67470.83470.7563AdaBoost0.93060.80000.49570.87360.3604Bagging0.98260.95320.78230.87880.8320Voteing0.98580.96040.80900.88280.93024结束语本文提出了一种融合文本图卷积和Stacking集成学习的文本分类方法(TGCN-S),以解决TextGCN特征利用不足的问题，提高文本分类准确率。不同于传统方法使用单个分类器对文本分类或者深度学习使用softmax直接对TextGCN提取的特征进行分类，TGCN-S采用Stacking集成学习，对TextGCN得到的特征进行二次学习，同时，去除Stacking集成学习中基分类器的交叉验证机制，加速模型拟合，最后通过融合层得到样本最后的分类。本文TGCN-S模型在R8、R52、MR、Ohsumed以及20NG等数据集上的准确率分别达到了98.58%、96.04%、88.28%、80.90%、93.02%,相对于其他模型有着很大的提升。实验结果表明，本文模型在文本分类方面具有较高的识别效果，同时也证明了本文方法的可行性。本文对于Stacking的基分类器参数只是凭借经验设置，并没有对这些参数进行优化，未来研究方向可以对这些基分类器的参数进行优化，以进一步提高整个模型的分类效果，提高模型的分类精度。同时图卷积学习到的特征表达缺少语句中的词序关系，因此丰富文本的特征表达也是未来研究方向之一。摘要：近年来恶意软件不断地发展变化，导致单一检测模型的准确率较低，使用集成学习组合多种模型可以提高检测效果，但集成模型中基学习器的准确性和多样性难以平衡。因此提出一种基于遗传规划的集成模型生成方法，遗传规划可以将特征处理和构建集成模型两个阶段集成到单个程序树中，解决了传统的恶意软件集成检测模型难以平衡个体准确率和多样性的问题。该方法以集成模型的恶意软件检出率作为种群进化依据，保证了基学习器准确性。在构建集成模型时自动选择特征处理方法、分类算法和优化基学习器的超参数，通过输入属性扰动和算法参数扰动增加基学习器的多样性，根据“优胜劣汰”的思想，进化生成具有高准确性和多样性的最优集成模型。在EMBER数据集上验证，结果表明，最优集成模型的检测准确率达到98.88%。进一步的分析表明，该方法生成的模型具有较高的多样性和可解释性。0引言恶意软件是当今互联网上最大的安全隐患之一，AVTEST的统计数据显示，2021年已发现的恶意软件数量已经达到约13.03亿，且仍在增加。国家互联网应急中心(CNCERT)发表的《2021年上半年我国互联网网络安全监测数据分析报告》指出，2021年上半年，捕获恶意程序样本约2307万个，日均传播次数达到582万次。因此，对恶意软件的检测一直是网络空间安全的重要课题之一。传统的恶意软件检测技术包括基于签名的检测方法和基于启发式的方法，这些方法需要专家分析恶意软件提取签名或制定规则进行检测，然而代码混淆和加壳等技术的出现，使恶意软件可以逃脱传统的检测技术，导致检测效率较低且难以识别。此外，恶意软件开发人员可以通过自动化恶意软件开发包创建数千个恶意代码，恶意代码数量剧增。使用人工分析恶意软件的难度越来越高。随着人工智能的发展，恶意软件检测技术开始和人工智能结合，以提高恶意软件的检测能力。近年来，机器学习[1~4]、深度学习[5~8]及集成学习[9~11]的方法开始被应用到恶意软件检测与分类。相比于传统的恶意软件检测技术，许多机器学习和深度学习方法极大地提高了恶意软件检测的准确率。但是由于恶意软件的不断发展变化，造成单模型的误报率、漏检率过高的问题。因此集成学习也被广泛应用于恶意软件检测方面，利用多个学习器组成集成学习模型以提高恶意软件检测的准确性。例如，GuoHui等人[10]将二进制数据转换为灰度图像，提取图像的GIST纹理特征以K近邻和随机森林方法作为基学习器，采用投票方法获得最终的恶意软件分类结果，通过集成学习有效提高了恶意软件的分类效果。在文献[11]中将全连接多层感知机和一维卷积神经网络作为基学习器，获得每个基学习器的预测结果，构成新的特征矩阵，使用该特征矩阵训练极限树，并作为元学习器，从而提高了恶意软件检测的准确性。上述研究表明，多个学习器集成可以进一步提高模型的检测能力。但是，集成检测模型的学习效果与基学习器的多样性和准确性息息相关。因此，如何在构建集成模型时保证其多样性和准确性仍然是当前研究难点。目前基于集成学习的恶意软件检测方案大致可以划分成恶意软件特征提取、特征处理、设计集成模型三个主要步骤。在特征提取阶段，从软件中提取一种或多种特征，如字节序列特征、文件头部信息等；之后在特征处理阶段，采用多种特征处理方法，从原始特征中学习更具分辨力的高级特征，如基于遗传编程的特征筛选[12]、信息增益等方法；在设计集成模型阶段，集成模型一般可分为两层，第一层是模型选择，即选择一种或多种分类算法作为基学习。第二层则是基学习器通过投票法、平均法等集成策略获得最终预测结果，或将基学习器的输出通过集成策略作为新的特征，如Stacking、Blending等，输入到元学习器中获得最终预测结果。目前大多数研究中这三个步骤是独立进行的，所有基学习器的输入特征一样，没有考虑不同特征组合对基学习器的影响，并存在特征冗余问题，导致基学习器的准确性较低，集成结果不理想。另外，在设计集成模型时，大多数集成学习模型都依赖于人工经验选择基学习器，存在集成模型多样性差的问题。此外，新的恶意软件在不断地出现和发展，一种分类算法很难有效的检测出所有恶意软件。所以利用集成学习来增强检测模型的准确性是目前最为有效的方法之一。如何在保证基学习器准确率的基础上，增加基学习器的多样性，产生更好的集成结果，仍是一个具有挑战性的问题。遗传规划(Geneticprogramming，简称GP)是由生物进化启发而来的一种进化计算技术，具有优秀的搜索能力，可以从终端集、功能集中选择叶子节点及内部节点生成多个解决方案，通过种群进化生成解决特定问题的最优解决方案[12]。在分类问题中，GP可以通过对训练集多次学习，在学习过程中来进化分类器。常用的基于GP的分类器通常将特征作为输入，输出一个浮点数，根据预定义的阈值对分类任务进行决策。因此可以先通过GP生成集成学习中的基学习器，之后利用现有的集成方法如bagging和boosting构建基于GP的分类器集成，保证集成学习中多样性和准确性，提高集成模型的性能。Karakatič和Podgorelec[13]开发了一种用于分类的方法，将AdaBoost和基于GP的分类器结合以提高模型性能，其中AdaBoost用于更新集成中的实例和每个基于GP的分类器的权重。Zhang,T[14]等人提出了EGPEL方法用于人脸识别，该方法自动构建集成学习模型，从而提高单个基学习器在人脸图像数据集上的性能。文献[15]中提出一种基于GP的特征构造集成分类方法。该方法将预提取的纹理、颜色、频率、局部和全局特征作为GP框架中分类器的输入，最终构建类间区分明显的特征和生成诊断结果更准确的集成模型。现有工作表明，基于GP生成的集成模型在分类任务上取得了较好的结果。但是，在恶意软件检测时，由于不同的任务在进行特征提取的需求和难度不同，大多数基于GP生成集成模型的方法不能直接用于处理恶意软件检测任务。此外，在恶意软件检测方面，遗传规划大多被用在特征处理阶段，获得最佳特征组合。如文献[16]设计了一种基于遗传规划的特征选择方法，与基于Filter的特征选择方法相比，该方法减小了机器学习模型的计算量，但是准确率不如基于集成学习的检测方法。因此，可以通过GP灵活的基于树的表示，将特征处理和设计集成学习模型两个阶段集成到单个GP树中，从而自动从原始样本特征演化出有效的识别恶意软件解决方案。然而，现有的基于GP生成集成模型的方法无法实现这一点。本文的总体目标是开发一种新的有效的基于GP的恶意软件集成检测模型生成方法(AGeneticProgramming-BasedMalwareIntegratedDetectionModelGenerationMethod，GPMD)，该方法自动学习原始特征和进化生成集成模型，保证基学习器的准确性和多样性。为了实现这一目标，设计了一个新的集成模型结构作为遗传规划中个体的表示。把特征处理相关操作、分类算法作为功能集，原始特征、分类算法相关参数等作为终端集，GPMD自动进化它们的组合以形成解决方案。每个解决方案都会为输入样本生成类别标签的组合预测。最终，在进化过程中演化出具有高准确率和多样性的最优集成检测模型。此外，该模型具有较高的可解释性，可以清晰的看到集成学习模型中每个基学习器所使用的特征组合，如何对原始特征进行处理。本文主要工作为a)提出了一种基于遗传规划的集成检测模型生成方法GPMD。该方法在生成集成模型时可以自动选择特征处理方法、分类算法和优化基学习器的超参数，通过输入属性扰动和算法参数扰动保证基学习器的多样性。将恶意软件的检出率作为GPMD中个体的进化依据，保证基学习器的准确性。b)设计了一个新的集成模型结构，该结构包含输入层、特征图像化层、图像加权融合层、特征学习层，特征融合层，基学习器选择层、集成层、和输出层，具有较高的可解释性。c)提出了一组适用于恶意软件检测的功能集和终端集，用于生成集成检测模型。本文提取了Ember数据集中样本的四种不同类型的特征，包括字节统计值(histogram，简称his)、字节熵(byteentropy，简称byte)、导入函数调用信息(imports，简称imp)和区段信息(section，简称sec)，作为GPMD种群中每个个体的输入。本文所提方法的包含两个模块，各个模块的功能和总体流程如下。a)GPMD最优集成模型生成模块：该模块用于生成最优集成模型。GPMD并不能直接对恶意软件进行检测，而是在预定义的功能集、终端集中选择不同的叶子节点和内部节点，采用混合法(rampedhalf-and-half)构造出多个集成模型[18]，组成初始化种群。之后对每个集成模型进行适应度评估，通过遗传操作算子产生的下一代种群，通过一代又一代的进化，获得最优集成检测模型。b)最优集成模型训练及测试模块：该模块分为两个阶段。在训练阶段，将训练集放入最优集成模型中，训练并保存模型。测试阶段则利用已经训练好的检测模型进行检测并输出检测结果。2方法实现设计生成恶意软件检测模型的GP算法时，需要考虑初始化种群时所需的功能集、终端集；用于评价模型好坏的适应度函数；种群中的个体表示(即集成模型结构)；终止条件以及GP参数五个基本要素。在本文中终止条件设为达到遗传代数，GP参数将在3.3节进行详细阐述。因此本章将分GPMD方法描述、个体表示与最优集成模型、功能集、终端集四个重要部分进行介绍。2.1GPMD方法描述GPMD方法的流程图如图1中模型生成过程所示，首先，将原始特征进行标准化处理，从终端集、功能集中选择叶子节点及内部节点生成多个集成模型，并组成初代种群。之后随机抽取样本输入到每个集成模型，加快种群中每个模型的收敛速度，计算种群中每个集成模型的适应度值，并将集成模型及适应度值记录到缓存表中，在进行下一代适应度评估时，如果下一代的集成模型在缓存表中，将适应值直接赋值给该模型，减少遗传规划在生成最优集成模型时的计算开销。随后判断是否达到种群迭代次数，若没有，则将种群中适应度值高的。个体通过精英保留策略复制到下一代种群，避免最优个体丢失。通过锦标赛选择算子从当前种群选取父代集成模型，在一定概率下，父代集成模型发生子树交叉、子树变异形成下一代新种群，重复上述操作，直到达到迭代次数，输出最优集成模型。GPMD具体算法描述如算法1所示。算法1GPMD最优模型生成算法输入：字节直方图(his)、字节熵直方图(byte)、导入函数(imp)和区段信息(sec)，遗传代数G，当前代数g，精英保留概率E，种群数量p。输出：最优集成检测模型。a)样本中每个特征值/该样本的总字节数，标准化his；采用最大最小归一化，标准化处理byte、imp、sec。b)使用genHalfAndHalfMD()从功能集和终端集中选择节点，生成p个集成模型，作为初始种群P0；c)创建记录表R，精英表BP；计算P0中每个集成模型的适应度值，存入R。使用无放回抽样的方法抽取1000个样本标准化后的原始特征作为当代种群的输入；ifnotBP：//判断精英表是否为null清空BP;根据精英保留策略，复制种群Pg中适应度值排名前E*p的个体及其适应度值，存入BP；通过锦标赛选择算子从Pg选择集成模型个体作为父系F；从F中选择集成模型进行子树交叉、子树变异操作生成子代Og+1；for每个集成模型oinOg+1：ifonotinR：使用适应度函数Fitness(I)计算适应度值；将集成模型o及其适应度值存入R；else：将R中的适应度值赋值给o的适应度值；BI与Og+1合并获得下一代种群Pg+1；g=g+1。e)输出BP中适应度最高的个体。适应度函数负责评价种群中每个集成模型的好坏，确定种群的进化方向以及寻找最优集成模型。针对恶意软件检测而言，恶意软件的检出率是最重要的一个指标，因此GPMD的适应度函数如式(1)所示。采用K折交叉验证法评估每个模型性能，每个集成模型将K(K=5)折交叉验证的平均结果作为该模型的适应度值。FMalnumMalallitness_/_=(1)其中Mal_num表示集成模型检测出的恶意软件数量，Mal_all表示样本中恶意软件总数。2.2个体表示及最优集成模型每个个体包含特征处理和构建集成模型两个阶段，为此设计了一个新的集成检测模型结构作为个体表示，如图2所示。该集成模型结构包括原始特征输入层、特征图像化层、图像加权融合层、图像特征学习层，特征融合层，基学习器选择层、集成层、和检测结果输出层。除了输入层和输出层，每一层都有不同的函数，实现对应的功能。输入层代表集成模型的输入，输入层的数据由终端集提供，具体内容将在2.4节详细阐述。恶意软件的特征处理阶段包含四层，首先将原始特征转换为灰度图像的特征图像化层，其次图像加权融合层将多张灰度特征图融合为一张图像，之后通过特征学习层提取多种图像特征，最后在特征融合层将多种图像特征连接形成高级特征向量。经过特征处理后的特征向量输入基学习器，获得基学习器的检测结果，并在投票集成层将多个基学习器检测结果通过投票获得最终结果输出。图3则是通过GPMD生成的最优集成模型，图中每一层的函数及其作用将在2.3节详细阐述。该集成模型融合了传统的恶意软件集成检测方法后两个阶段，将特征处理、设计集成模型两个过程相连接，使输入每个基学习器的特征不再是相同的组合，而是可以进一步提高基学习器准确性的最佳特征组合，且不同基学习器最佳特征组合也不同。如图3最优集成模型所示，在最左边的分支上每个样本原始特征经过Encode转换为三张16*16的灰度图像，之后Weight_img将三张灰度图像加权融合为一张图像。经过卷积池化操作最终获得64维的高级特征向量，在特征融合阶段与局部特征sec拼接形成一个74维特征向量输入到ERF进行训练。在第二棵子树中，每个样本经过特征学习层HOG函数获取图像的梯度特征，之后和局部特征sec融合成35维高级特征向量输入到基学习器进行训练。而第三棵子树输入基学习器的高级特征向量维数为100，该特征向量由三种类型构成，包括由LBP函数提取的58维纹理特征、sec样本局部特征、卷积池化层提取的32维特征向量。该模型可以清晰的看到每个基学习器所使用的特征组合，以及这些特征组合如何产生，因此比其他恶意软件检测方法具有更高的可解释性。特征图像化层采用两种编码方式，将恶意软件原始特征his、byte、imp转换为灰度图像，使模型对代码混淆具有一定的适应能力。输入是标准化处理后的多个类型的恶意软件特征，输出是灰度图像。主要使用两种图像化函数，一种是直接编码Encode函数，将标准化处理后的原始特征与255相乘转换为16*16的灰度图像。另一种采用双字节编码Byte_Encode函数，首先将标准化后的原始特征中每一个特征值转换为二进制，之后将小数点向右移动16位，每八位转换为一个像素值。如某个标准化后的特征值为0.023458，经过双字节编码转换为像素值6，1，经过双字节特征编码转换为灰度图像，减少精度损失，原始特征扩大一倍变为此外，GPMD通过输入属性扰动和算法参数扰动两种方法，使进化生成的最优集成模型具有很高的多样性。如在特征处理过程中，每层使用不同函数获取不同的高级特征向量，之后这些特征向量作为基学习器的输入，训练出不同的基学习器。在GPMD中将基学习器的参数设为叶子节点，可以在进化学习过程中自动调整参数，实现算法参数扰动。如图3中，中间及右边两棵子树虽然均使用LightGBM分类算法作为基学习器，但是两者所使用的算法参数、算法所使用的特征向量均不相同，训练出基学习器也会产生较大差别。2.3功能集功能集是GPMD的关键组成部分之一，它构成了GPMD中每个集成模型树的内部节点，根据每一层的作用，在功能集中有六种不同类型的函数，每层函数如表1所示。本节将从下到上介绍每一层的功能及其函数。表1函数集Tab.1Functionset功能层函数特征图像化Encode、Byte_Encode图像加权融合Avg_img、Weight_img特征学习Cov1、MaxP、AvgP、Mix_Cat、Mix_Add、LBP、HOG、SIFT特征融合层FeaCon2、FeaCon3、FeaCon4、FeaCon5基学习器选择层SVM、LR、RF、ERF、LightGBM集成层Combine3、Combine516*32的灰度图像，某个样本图像化结果如图4所示，其中图4(a1)(a2)(a3)采用Encode函数对his、byte、imp三个特征图像化，图4(b1)～（b3)采用Byte_Encode函数对his、byte、imp三个特征图像化。图像加权融合层主要功能是对输入的三张特征图像融合，减少集成模型的计算量。输入为三张灰度图像X、Y、Z，输出为一张灰度图像。设计了两种融合的函数，一种是Avg_img认为每个类型特征重要性相同，融合公式为AvgimgXYZ_()/3=++。另一种方法Weight_img，考虑到在恶意软件中，不同类型特征的重要性不同，该函数对三个特征赋予不同的权重进行融合。融合公式为WeightimgXYZ_(*299*587*144500)/1000=+++。将图4的样本灰度特征图融合结果如图5所示，其中X代表byte、Y代表his、Z代表imp。通过图4、图5对比发现，融合后的灰度图像所含信息更为丰富，同时减小了模型计算量。特征学习层可细分为卷积、池化及传统的图像处理算子，用于提取图像中不同类型的特征。它们以图像作为输入，输出是一维特征向量。卷积层函数为Cov，在该函数中图像通过与卷积核的矩阵运算，得到比像素值更高级的特征。后经过多种池化层函数，如最大池化MaxP、平均池化AvgP、组合池化Mix_Cat、Mix_Add提取卷积后图像特征，降低特征信息冗余。传统的图像处理算子包括LBP函数、HOG函数、SIFT函数。LBP函数采用圆形LPB算子生成LBP图像，将采样点设为8，提取像素块与其邻居之间的关系生成一个58维特征。HOG函数则是提取图像一定区域大小的直方图特征并进行归一化，区域大小作为GPMD的叶子节点，并在终端集中设置取值范围，具体描述在2.4节。Fig.5ImageweightedfusionexampleSIFT函数则是从图像中检测关键点，并从中提取128维特征。该层中每个图像特征提取函数可以提取到不同数量的特征，经过特征学习后的使得特征更加紧凑，能够抵抗噪声干扰。特征融合层的函数分为FeaCon2、FeaCon3、FeaCon4、FeaCon5四种，可以分别将两个、三个、四个、五个向量融合，形成一个新的特征向量，输入到基学习器中。该层函数输入为经过特征学习层生成的特征、Sec局部特征，输出为一个一维特征向量。在基学习器选择层，为了减少搜索空间，主要采用了支持向量机(SVM)、随机森林(RandomForest，RF)、极端树(ExtraTree，ERF)、逻辑回归(LR)和LightGBM五个在恶意软件检测方面最常用的分类算法，并将每个分类算法的参数设为GPMD的叶子节点，使其在进化过程中自动优化，这些关键参数将在2.4节中详细介绍。集成层层函数为Combine3和Combine5，在集成学习中常用的集成策略分为平均法和投票法两种，而恶意软件检测属于分类任务，且GPMD生成集成模型既可能是同质集成也可能异构集成，因此采用投票法对基学习器结果进行集成更为合适。输入可以是单个基学习器的预测标签，也可以是多个基学习器集成后的预测标签。输出是每个样本的预测标签。2.4终端集终端集表示GPMD中个体即集成模型的输入，如表2所示。表2终端集Tab.2Terminalset参数类型含义hisArray字节统计特征byteArray字节熵特征impArray函数调用特征secArray区段特征LabelArray样本标签filterArray卷积核权值，范围是[-0.2,0.2]filter_sizeInt卷积核大小，可选3/5/7rFloat圆形LBP算子半径，范围[1,3]sizeInt池化及求HOG特征平均值范围，范围[2,4]CIntLR和SVM的正则项参数为10-c，范围[-5,-2]lrFloatLightGBM分类算法的学习率，范围[0.05,0.1]nIntLightGBM分类算法的迭代次数范围[100,1000]，步长50tree_numIntRF、ERF分类算法的子树个数，范围[100,1000],步长50max_depthIntRF、ERF分类算法的最大深度，范围[10,100],步长10his、byte、imp、sec表示从数据集中提取到的原始特征，除sec外其他三个特征大小为600000*256(训练集样本数*特征向量维数)，sec为600000*10。Label表示数据集样本标签，0表示良性样本、1表示恶意样本。filter、filter_size、r、size是特征学习层函数的重要参数，filter表示卷积核的权值。filter_size表示卷积核大小，常用大小为3*3、5*5及7*7。r为圆形LBP算子的半径，其范围为[1,3]。Size取值范围[2,4]，表示池化范围以及计算HOG算子平均特征值时的区域大小。此外，基学习器的重要参数也被设计为GPMD的终端，包括分类算法SVM和LR的正则化参数10(-C)，C的取值范围是[-2,5]。LightGBM分类算法的稳定性和准确性取决于学习率(lr)和迭代次数(n)这两个重要参数，lr常用的取值范围为[0.05,0.1],n的常用取值范围为[100,1000]。RF和ERF中重要参数是子树个数(tree_num)及最大深度(max_depth)，因此tree_num及max_depth也作为输入，它们范围分别是[100,1000]、[10,100]，为了避免GPMD的搜索空间过大，tree_num在其范围内步长为50的增加或减少，max_depth在其范围内步长为10的增加或减少3实验结果与对比分析3.1数据集EMBER数据集[19]是基于PE格式的恶意软件检测基准数据集之一，该数据集包含40万个良性样本、40万个恶意样本、30万未知样本。考虑到恶意软件原始文件公开会带来各种安全问题，EMBER的发布者并没有公开原始文件，而是提供了可以反映原始文件的原有特性的一些特征及其标签。数据集中每个样本保存为一个JSON对象，每个对象的特征数据包含sha256哈希值、出现时间(appeared)、标签(label)、通用文件信息(general)、头部信息(header)、导入函数(imports)、导出函数(exports)、区段信息(section)、字节直方图(histogram)、字节熵直方图(byteentropy)、字符串信息(string)这些字段。其中标签1代表恶意软件、标签0代表良性样本、标签-1表示未知样本，研究者们可以从这些原始特征中提取特征向量及样本标签。本文提取导入函数(imports)、字节直方图(histogram)、字节熵直方图(byteentropy)、区段信息(section)这四个字段信息转换为四个特征向量，作为GPMD和最优集成模型的输入。在本实验中，剔除未知样本(标签为-1)，剩余80万样本中，60万个样本作为模型生成和最优集成模型性能测试时训练集，20万样本作为最优集成模型性能测试的测试集。3.2实验环境及评价指标本文的实验环境如下：硬件环境为i9-10900XCPU@3.70GHz，RAM30.0GB；软件环境为Linux系统，python3.8，deap1.3.1，scikit-learn0.24.2以及其他工具包。为了充分评估模型的性能，本文选用恶意代码检测领域的四个常用评测标准，准确率(Accuracy)、召回率(Recall)、查准率(Precision)、F1值以及检测时间多方面对最优集成模型进行评估。3.3GP参数设置由于CPMD中个体结构每一层功能函数及相关参数选择较为灵活，为了获得表现更好的个体，因此种群大小设为1000，生成尽可能多的集成模型。其余参数本文根据文献[20]及经验设置GPMD的参数如表3所示。在GPMD中，种群初始化后，每一代种群通过锦标赛选择用于在进化学习过程中选择进行变异和交叉的父代个体，该过程利用基于Python中的分布式进化算法[21]实现。表3GP参数设置Tab.3GPparametersettings参数值参数值种群大小1000遗传代数50精英选择概率0.01交叉率0.9突变率0.2锦标赛选择个体7GPMD可以通过种群遗传迭代来提高集成分类器的性能，遗传代数太小，种群进化不成熟，集成分类器性能达不到最优；遗传代数太大，种群中已存在最优集成模型，继续进化没有意义，只会增加时间开支和资源浪费。本文在实验中记录了GPMD中遗传代数与每一代集成检测模型平均准确率之间的关系如图6，通过图6发现当迭代次数到达50时，平均准确率趋于平稳，表明种群已经出现最佳解决方案即最优集成模型。图6遗传代数与集成检测模型平均准确率关系Fig.6Relationshipbetweengenerationandaverageaccuracyofintegrateddetectionmodel3.4实验结果与分析为了充分证明最优集成检测模型图3的实际效果，本文对比的基准方法为SVM、LR、RF、ERF、AdaBoost、LightGBM、CNN、文献[10]的集成模型、文献[22]的集成模型。其中，基准方法SVM、LR、RF、ERF、AdaBoost、LightGBM是基于机器学习包scikit-learn实现的，相关参数则是此包中网格搜索GridSeachCV方法选择最优超参数组合，以获得最好的模型表现，相关参数的范围与GPMD所使用的范围一致。这些基准方法输入为标准化后的his、byte、imp、sec四个原始特征。CNN方法则是通过Tensorflow实现，网络结构及参数参考文献[17]，其将原始特征转换为28*28的灰度图片，输入到CNN模型中。文献[10]的集成模型输入为28*28的灰度图像全局纹理特征，基础分类参数及集成策略与文献[10]一致。根据文献[22]中不同类型特征采用不同类型的基学习器和集成策略，his、byte属于非PE特征，sec、imp属于PE特征，依据文中基学习器表选择不同的基学习器并采用Stacking集成策略，非PE特征将SVM作为元学习器，PE特征将KNN作为元学习器，最终将两者结果依照文献[22]中权重投票策略获得最终预测结果。实验结果与表4所示表4不同分类算法检测效果对比Tab.4Comparisonofdifferentclassificationalgorithms分类算法评价指标Accurary(%)Recall(%)Precision(%)F1-Score(%)SVM77.4486.7579.3782.91LR73.4872.6373.9373.27RF95.0390.1186.5393.72ERF94.9193.0688.7190.86AdaBoost86.784.2788.5786.37LightGBM95.8696.3893.6395.04CNN97.897.0398.4197.61文献[10]96.8195.3894.1594.78文献[22]96.9994.4590.0492.19本文模型98.8898.5499.1298.88通过实验结果对比分析，发现本文模型无论是Accuracy、Recall、Precision还是F1-Score都显著高于其他机器学习模型。相比于RF、ERF、AdaBoost、LightGBM这些基于树的单一集成学习模型，本文通过GBMD生成的最优集成检测模型在F1值上分别高出5.16%、8.02%、12.51%、10.48%和3.84%。与其他恶意软件集成检测模型相比，本文提出的集成模型具有更好的检测效果。除了考虑模型的分类性能外，本文对GPMD生成最优集成模型和其他机器学习模型使用网格搜索参数调优的时间进行对比分析，如图7所示，每个模型在相同的软硬件环境下进行参数调优。图7获得最优检测模型的时间对比Fig.7Timecomparisonofoptimaldetectionmodel本文对上述不同分类算法获得的表现最好的模型的运行时间进行分析比较(本文模型的运行时间是指模型训练完后，在测试集上进行预测，单个样本所使用的时间)，具体结果如图8所示。图8不同模型检测时间对比Fig.8Comparisonofdetectiontimeofdifferentmodels图7、图8对比发现，GPMD生成最佳集成模型的时间与常见的集成学习算法RF、ERF、LightGBM获得最优超参数组合的时间接近，最优模型检测时间分别相差0.0061s、0.0017s、0.0098s，但是这三个模型检测准确性不如本文模型。单个机器学习模型如SVM、LR参数调优和检测耗时较短，但是检测准确率偏低。结合表4对比分析其他集成检测模型，发现本文的模型在保证检测效果最好的情况下拥有较短的检测时间，获得最优集成模型所耗费的时间也在可接受范围内。此外，为了进一步验证通过GPMD生成的最优集成模型的有效性，本文获取最优集成模型中三棵子树的评价指标。并将第二棵子树的基学习器换为RF，其他参数即函数节点不变，该集成模型记为模型1，获取模型1的评价指标，实验结果如表5所示。最优集成检测模型中子树所使用的基学习器为ERF、LightGBM，各项指标均优于表4中ERF、LightGBM的检测效果，表明经过GPMD进化生成的特征组合提高了分类算法的检测准确率。而三棵子树通过投票函数提高了整个模型的检测准确率，各项评价指标均高于模型1，也进一步表明GPMD在进化过程中可以找到较好的集成方案。综上所述，GPMD在进化过程中会为每个基学习器选择不同的特征组合，并找到较好的基学习器集成方案，使最终生成的最优集成模型不仅具有高准确率，而且具备较高的多样性。表5最优集成模型中子树检测效果对比Tab.5Comparisonofsubtreedetectioneffectsinthebestensemblemodel子树评价指标Accurary(%)Recall(%)Precision(%)F1-Score(%)左边子树95.9194.0692.7193.41中间子树96.3796.5894.6395.59右边子树96.6397.1195.5396.34模型197.3996.0595.1395.614结束语本文将遗传规划算法应用于恶意软件检测领域，提出了一种基于遗传规划的恶意软件集成检测模型生成的方法，并设计了一种集成模型结构用于表示GPMD中的个体。GPMD方法将恶意软件检测的特征处理与构建集成模型两个过程融合在一个GPMD个体中，可以从原始特征中获得最佳特征组合，自动优化分类器中的参数，使集成模型中的基学习器可以在进化过程中增加其多样性并保证准确性。之后将GPMD生成的最优集成模型与多个模型性能对比实验分析，结果表明，本文经过GPMD生成的最优集成模型比其他检测模型有更好的性能。此外，进一步分析表明，针对恶意软件检测，GPMD方法可以有效地生成高准确性、多样性和高可解释性的集成模型。由于目前恶意软件检测相关的数据集有限，未能充分体现出本文方法所生成的最优模型在其他数据集上的可扩展性。下一步将考虑收集更多的恶意软件数据集，通过多数据集融合，采用多种集成策略，探究通用性更强的集成模型。此外，未来将考虑将该方法用于恶意软件分类领域，为评估恶意软件的危险性提供参考。