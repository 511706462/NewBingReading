摘    要：
由于word2vec、Glove等静态词向量表示方法存在无法完整表示文本语义等问题，且当前主流神经网络模型在做文本分类问题时，其预测效果往往依赖于具体问题，场景适应性差，泛化能力弱。针对上述问题，提出一种多基模型框架(Stacking-Bert)的中文短文本分类方法。模型采用BERT预训练语言模型进行文本字向量表示，输出文本的深度特征信息向量，并利用TextCNN、DPCNN、TextRNN、TextRCNN等神经网络模型构建异质多基分类器，通过Stacking集成学习获取文本向量的不同特征信息表达，以提高模型的泛化能力，最后利用支持向量机(support vector machine, SVM)作为元分类器模型进行训练和预测。与word2vec-CNN、word2vec-BiLSTM、BERT-TexCNN、BERT-DPCNN、BERT-RNN、BERT-RCNN等文本分类算法在网络公开的三个中文数据集上进行对比实验，结果表明，Stacking-Bert集成学习模型的准确率、精确率、召回率和F1均为最高，能有效提升中文短文本的分类性能。

文本分类一直是自然语言处理领域的重要研究课题，传统机器学习算法文本特征表达能力较弱，需要进行特征工程提取，基于海量大数据支撑的深度学习算法面临着对具体问题的强依赖性。而中文短文本具有特征词汇较少，词意复杂和特征稀疏等特点，现有文本分类算法的预测效果往往依赖于具体问题，不同场景状态下算法适应能力较弱，引起了中外学者的广泛关注[1,2,3]。

徐清越等[4]提出一种融合双维度卷积神经网络(two-dimensional convolutional neural networks, TD-CNN)和位置自注意力机制(positional attention mechanism, PO-ATT)的文本分类模型，提取文本向量的丰富语义特征，根据词语和字符两种不同嵌入级别的特征向量表达进行语义分类研判。随后，陈可嘉等[5]提出一种基于全局词向量表示(global vectors for word representation, Glove)和隐含狄利克雷分布(latent dirichlet allocation, LDA)主题模型的文本表示改进方法，训练隐含主题信息和相应概率信息分布的主题向量，计算两者相似性作为输入。相比传统语义分类模型，上述方法在一定程度上提升了文本分类器的性能。沈雅婷等[6]提出一种基于自举汇聚法的文本分类多基模型框架(bagging fastText, B_f),以fastText为基础框架，运用集成学习思想，设置最优超参数组成多基模型，再通过投票机制确定文本最终类别，在大规模有监督文本分类任务中表现出了较好的普遍适用性。上述研究工作基于word2vec或Glove等静态词向量展开，在解决短文本分类问题时仍存在一定的局限性。近期，随着预训练语言模型的广泛应用，越来越多的学者开始将其用于文本的深层语义抽取，段丹丹等[7]提出一种基于预训练语言模型(bidirectional encoder representations from transformer, BERT)的中文短文本分类模型，利用Transformer双向编码器在句子层面进行特征向量表示，在中文短文本分类任务中表现出了更好的模型性能。在此基础上，崔文武等[8]提出一种基于BERT模型的诉讼案件违法事实要素自动抽取方法，并引入循环神经网络对文本进行编码，提取上下文相关的语义信息。张翼翔等[9]提出一种基于BERT-BIGRU-ATT模型的短文本分类方法，利用BERT预训练语言模型提取文本字向量，并引入双向门控神经单元(bidirectional gated recurrent unit, Bi-GRU)和注意力机制(attention, ATT),强化学习短文本的上下文语义特征。

综合上述分析，现提出一种用于中文短文本分类的多基模型框架Stacking-Bert, 通过集成多个异质基分类器实现文本向量的训练和预测。该模型采用BERT预训练语言模型对大量中文语料库进行预训练，得到融合词语本身和上下文语义信息的动态词向量表示，并将获得的短文本字向量与TextCNN、DPCNN、TextRNN、TextRCNN等神经网络模块相结合，运用Stacking集成学习思想，对多个异质基分类器设计一个元分类器模型进行训练和分类，以期解决现有文本分类算法适应各场景能力较弱，分类准确率较低的问题。

1.1 Stacking集成学习模型
Stacking集成学习算法是一种通过构建一个元分类器模型来整合多个基分类模型的集成学习技术，通过将若干个具有学习能力较强和差异性较大的基分类器模型组合成一个强分类器，以此提升模型的泛化能力。Stacking集成通常包含多个不同的基模型和一个元模型。基分类器模型利用整个训练集进行训练，元分类器模型将多个异质基分类器模型的输出特征作为输入特征进行训练，模型框架结构如图1所示。

图1 Stacking集成学习算法框架
图1 Stacking集成学习算法框架   下载原图

Fig.1 Stacking integrated learning algorithm framework

Stacking集成学习将训练好的基模型对整个训练集进行预测，将样本预测结果作为新训练集的特征值进行训练。在集成学习中，每个基分类器模型的学习能力和算法差异性是影响Stacking集成学习算法性能的关键因素，为了能够最大程度地发挥集成模型性能，基分类器模型在保持强学习能力的同时需要具备一定的异质性，从而提取不同的特征信息表达。最终得到的集成学习模型将具有兼顾基分类器和元分类器的算法学习能力，使得集成模型的预测准确率得到进一步提升。

1.2 BERT预训练语言模型
BERT预训练语言模型是Devlin等[10]提出的一种动态词向量表示方法，采用多层双向的Transformer编码器对大量中文语料库进行预训练，在文本句子层面可以得到融合词语本身和上下文语义信息的动态词向量表示，模型结构如图2所示。

BERT模型采用多层Transformer编码器设计，Transformer编码器是一个采用了多头自注意力机制(multi-head attention)的Seq2Seq序列模型，模型结构为Encoder-Decoder。BERT模型利用多层Transformer结构和多头自注意力机制对大量文语料库预训练，将中文文本输入映射为动态词向量表示，相比基于传统的静态词向量表示方法，能够更好地解决中文短文本中存在的同义词、近义词以及一词多义现象，从而实现更为完整的语义特征表达。

图2 BERT模型结构示意图
图2 BERT模型结构示意图   下载原图

Fig.2 Schematic diagram of BERT model structure

E1,E2,…,EN为文本序列输入向量；Trm为Transformer编码 器结构组件；T1,T2,…,TN为BERT模型输出的动态词向量

1.3 基分类器模型
由于中文短文本具有特征稀疏、维度不足等特征，在使用BERT模型进行文本字向量表示的基础上，采用当前主流的4种神经网络分类模型来构造Stacking集成学习的基分类器，主要包括TextCNN经典卷积神经网络模型、DPCNN新型卷积神经网络、RNN循环神经网络以及RCNN混合神经网络模型。

(1)TextCNN文本卷积神经网络[11]是一种经典的文本分类算法，Kim等[12]首次将卷积神经网络应用到文本分类领域，采用多个不同大小的卷积核在句子层面对文本词汇进行卷积操作，能够有效提取短文本的词级特征信息。

(2)DPCNN新型卷积神经网络[13]针对TextCNN模型不能学习文本的长距离依赖关系的不足，通过不断增加网络深度，从而有效地抽取文本的长距离依赖关系。

(3)RNN循环神经网络[14]在每一个时间步长上输入文本序列中的一个词向量表示，计算当前时间步长上的隐藏状态，然后当前时间步长下的输出传递给下一个时间步长，结合下一个时间步长的词向量一起作为RNN网络单元的输入，再计算下一个时间步长上的RNN隐藏状态，从而学习文本序列的上下文依赖关系。

(4)RCNN混合神经网络模型[15]结合了RNN和CNN两个网络模块用于文本分类，同时考虑每个词的词向量和上下文的依赖关系，共同构成词向量的最终嵌入表示。

TextCNN、DPCNN、RNN和RCNN神经网络采用具有不同的网络结构设计进行文本向量的特征提取，TextCNN注重于文本词汇特征信息捕捉，DPCNN注重于文本的长距离关系抽取，RNN注重于学习文本序列的上下文依赖关系，RCNN结合RNN和CNN两个模块设计，充分考虑每个词的词向量和上下文的向量表示。针对不同的目标任务的关注点，该4种神经网络模块有着自身独特的算法优势，且具有不同的场景适应能力，在多项自然语言处理(natural language processing, NLP)任务中均有着良好的表现。

2 基于Stacking-Bert的短文本分类
2.1 Stacking-Bert多基模型框架
深度学习算法在文本分类领域得到了广泛应用，但其分类效果往往依赖于具体问题。集成学习通过综合多个异质基分类器来预测结果，具有更强的场景适应能力和更高的分类准确率。基于Stacking集成学习思想，提出一种Stacking-Bert多基模型框架的中文短文本分类算法，充分考虑多个基分类器模型之间的差异性和学习能力，对BERT模型进行网络结构微调，在BERT模型内部的Transfomer编码器后面嵌入TextCNN、DPCNN、RNN和RCNN神经网络模块实现网络层的融合，最终形成5种基模型分类器，分别为：BERT-Base、BERT-TextCNN、BERT-DPCNN、BERT-RNN和BERT-RCNN,其中，“-”表示把BERT预训练语言模型的最后一层Transformer结构的输出分别输入到对应的下游任务神经网络层中，BERT-Base表示BERT模型本身的原始输出，模型结构如图3所示。

其中，BERT模型采用多层双向Transformer编码器对大量中文预料库进行训练，可以得到融合词语本身和上下文语义信息的动态词向量表示，在一定程度上可以解决短文本的特征稀疏和一词多义问题。卷积神经网络(CNN)可以有效捕获文本的词级结构信息，循环神经网络(RNN)可以学习文本的上下文依赖关系，是文本特征提取的经典神经网络结构。本文研究设计Stacking-Bert多基模型框架第一层基分类器选择BERT-Base、BERT-TextCNN、BERT-DPCNN、BERT-RNN和BERT-RCNN神经网络模块进行训练得到模型预测结果，第二层元分类器采用支持向量机实现输入向量从低维空间到高维空间的映射，用于对第1层基分类器模型学习结果的集成分类，充分考虑性能较好模型具有的优势和性能较差模型带来的偏差，从而提高模型的泛化能力和场景适应能力。

图3 Stacking-Bert多基模型框架
图3 Stacking-Bert多基模型框架   下载原图

Fig.3 Stacking-Bert multi-base model framework

2.2 算法描述
基于Stacking-Bert多基模型框架的集成学习算法伪代码如下。

导出到EXCEL


算法1 Stacking-Bert集成学习算法
输入:训练集D={(x1,y1),(x2,y2),…,(xm,ym)};
基分类器模型ζ1,ζ2,…,ζT;
元分类器模型ζ。
过程:
1: for t=1,2,…,T do
2: ht=ζt(D);
3: end for
4: D′=∅;
5: for i=1,2,…,m do
6: for t=1,2,…,T do
7: zit=ht(xi);
8: end for
9: D′=D′∪((zi1,zi2,…,ziT),yi);
10: end for
11: h′=ζ(D′);
输出:集成模型H(x)=h′(h1(x),h2(x),…,hT(x))。
3 实验结果与分析
3.1 数据集介绍
为测试各模型的短文本分类效果，采用网络公开的三个中文数据集，分别包括搜狗新闻THUCNews_data, 新浪微博simplifyweibo_moods, 京东评论Jingdong_data。其中搜狗新闻数据集包含10种新闻类别，共计200 000条。新浪微博数据集包含喜悦、愤怒、厌恶和低落4种情感类别，共计361 744条。京东评论数据集为网上手机购物的正负评论，包含好评、中评、差评3种类别，共计3 000条。选取的3类数据集可以测试模型分别在大规模数据样本下和小样本数据集下的性能表现。随机选取其中80%的数据样本作为训练集，10%作为验证集，剩余10%作为测试集。为了测试模型的泛化能力，各标签类别数据保持一定程度的不平衡性，三个中文数据集的概况如表1所示。

表1 数据集统计表 导出到EXCEL

Table 1 Data set statistics table


数据集	训练集	测试集	验证集	类别

搜狗新闻	180 000	10 000	10 000	10

新浪微博	289 396	36 174	36 174	4

京东评论	2 400	300	300	3
3.2 对比实验
采用当前主流的深度学习文本分类算法作为对比实验，包括word2vec-CNN、word2vec-BiLSTM、BERT-texCNN、BERT-DPCNN、BERT-RNN、BERT-RCNN等文本分类算法。

(1) word2vec-CNN和word2vec-BiLSTM文本分类算法采用word2vec词向量表示方法，然后把词向量分别输入到CNN模型和BiLSTM模型中再次进行特征信息提取，最后通过softmax进行分类，是目前常用的文本分类算法。

(2) BERT-TexCNN、BERT-DPCNN、BERT-RNN和BERT-RCNN文本分类算法采用BERT预训练语言模型进行字向量表示，分别以TexCNN、DPCNN、RNN和RCNN作为下游任务进行特征提取，相比word2vec词向量表示方法，提升了模型性能。

3.3 评价指标
为了衡量本文所提模型的有效性，采用精确率(Precision)、召回率(Recall)和Micro-F1衡量模型的分类性能，其定义为

Precission=TPTP+FP         (1)

Recall=TPTP+FN         (2)

Micro−F1=2Precision×RecallPrecision+Recall         (3)

式中：Precision代表预测结果为正例的情况中预测正确的比例；Recall代表实际结果为正例的情况中预测正确的比例。Micro-F1同时考虑标签预测精确率和召回率，是两者的调和平均值，也是衡量不平衡数据集的重要指标。

3.4 参数设置
基于Stacking-Bert集成学习的中文短文本分类方法，将中文短文本的长度处理为32,采用BERT模型进行动态词向量表示，并运用Stacking集成学习思想，利用TextCNN、DPCNN、RNN和RCNN等算法构造多个基分类器，模型训练过程中设置最大迭代次数epochs为20,一个批次训练样本为128,学习率为0.001。此外，为了保证模型的正常迭代，设置若连续输入超过1 000个训练样本，模型效果还没有提升，则提前结束训练。模型参数详细设置如表2和表3所示。

表2 Stacking集成学习的特征参数 导出到EXCEL

Table 2 Feature parameters of Stacking ensemble learning


模型参数	参数值

文本长度	32

字向量维度	300

Channels队列数	250

Dropout随机丢弃概率	0.5

TextCNN、DPCNN滤波器大小	(2,3,4)

RNN隐藏层神经元个数	128

RNN堆叠层数	2

RCNN隐藏层神经元个数	256

RCNN堆叠层数	1
表3 BERT模型参数设置 导出到EXCEL

Table 3 BERT model parameter settings


模型参数	参数值

Embedding词向量维度	128

隐藏层单元个数	768

多头自注意力机制的Head数	64

隐藏层数	12

激活函数	gelu

学习率	0.000 05

隐藏层Dropout概率	0.1
使用Google提供的BERT-Base预训练语言模型，采用12层网络结构设计，隐藏层维数设置为768,采用Multi-Head Self-attention(head=12)。BERT模型训练参数设置如表3所示。

3.5 模型对比
为了有效评估本文所提基于Stacking-Bert集成学习模型在中文短文本数据集上的分类性能，对比了当前主流的基于深度学习的文本分类算法，所有对比模型采用相同的模型参数设置和评价指标进行模型性能的衡量。为了防止实验结果的偶然性，对模型运行10次计算均值，得出的对比实验结果如表4所示。

如表4所示，采用word2vec词向量表示方法的文本分类模型在三个数据集上的分类准确率最低，分别为0.87、0.68和0.64,这是由于word2vec静态词向量模型在解释文本一词多义、上下文依赖关系、序列结构特征等信息方面存在不足，而基于BERT模型的文本分类准确率整体得到了大幅度的提升，达到了0.94、0.88和0.85,说明BERT模型能有效地捕捉文本的深层信息特征。本文所提Stacking-Bert集成学习在BERT模型下游任务采用了不同的神经网络结构提取文本不同的信息特征表达，然后基于一个元学习器实现文本的分类预测，在搜狗新闻、新浪微博和京东评论三个数据集上都达到了最好的F1,分别为0.96、0.91和0.89,验证了Stacking-Bert集成学习对中文短文本分类的有效性。

表4 模型分类精确率 导出到EXCEL

Table 4 The Precision rate of model classification


模型	评测指标	搜狗新闻	新浪微博	京东评论

word2vec-CNN	召回率
(Recall)	
0.87	0.68	0.62

word2vec-BiLSTM	
0.86	0.64	0.60

BERT-TextCNN	
0.94	0.89	0.85

BERT-DPCNN	
0.95	0.89	0.85

BERT-RNN	
0.95	0.86	0.83

BERT-RCNN	
0.94	0.88	0.86

Stacking-Bert	
0.96	0.91	0.89

word2vec-CNN	精确率
(Precision)	
0.88	0.68	0.68

word2vec-BiLSTM	
0.87	0.65	0.61

BERT-TextCNN	
0.94	0.90	0.85

BERT-DPCNN	
0.94	0.88	0.86

BERT-RNN	
0.95	0.86	0.83

BERT-RCNN	
0.95	0.89	0.85

Stacking-Bert	
0.96	0.91	0.90

word2vec-CNN	F1
(Micro-F1)	
0.87	0.68	0.64

word2vec-BiLSTM	
0.87	0.64	0.60

BERT-TextCNN	
0.94	0.89	0.85

BERT-DPCNN	
0.94	0.88	0.86

BERT-RNN	
0.95	0.86	0.83

BERT-RCNN	
0.94	0.88	0.85

Stacking-Bert	
0.96	0.91	0.89
此外，实验结果表明，基于深度学习的文本分类效果在大规模搜狗新闻数据集上明显优于小样本京东评论数据集，表现出了深度学习算法对具体问题的强依赖性，而Stacking-bert集成模型在一定程度上减少了上述差距。

4 结论
研究了一种基于Stacking-Bert集成学习的中文短文本分类方法。采用BERT预训练语言模型进行文本字向量表示，并将获得的短文本字向量与TextCNN、DPCNN、TextRNN、TextRCNN等神经网络模块相结合，提取不同的特征信息表达。然后运用Stacking集成学习思想，通过集成多个基分类器实现短文本的训练和预测，与word2vec-CNN、word2vec-BiLSTM、BERT-texCNN、BERT-DPCNN、BERT-RNN、BERT-RCNN等算法进行对比实验，该模型在精确率、召回率和整体F1等评价指标上均优于其他模型，对中文短文本的分类研究提供了一定的参考价值。

BERT模型采用多层双向Transformer编码器对大量中文预料库进行训练，可以得到融合词语本身和上下文语义信息的动态词向量表示，在一定程度上可以解决短文本的特征稀疏和一次多义问题。TextCNN、DPCNN、TextRNN、TextRCNN基分类模型在保持算法强学习能力的同时具备一定的异质性，Stacking集成学习基于所有训练好的基模型的预测构造新的测试集，再对测试集进行预测，具有更好的泛化能力，能有效提升文本的分类精度，在特定领域的文本分类任务中具有非常高的应用价值。在下一步工作中，将针对大规模数据集探讨集成算法的复杂度问题，并针对大型数据集训练过程中造成的时间消耗和计算资源消耗，尝试使用分布式训练方法完成对基分类器模型的训练，在保证模型精度的同时提高模型训练效率。


摘    要：
为了提高文本分类的准确率并解决文本图卷积神经网络对节点特征利用不足的问题，提出了一种新的文本分类模型，其内在融合了文本图卷积和Stacking集成学习方法的优点。该模型首先通过文本图卷积神经网络学习文档和词的全局表达以及文档的语法结构信息，再通过集成学习对文本图卷积提取的特征进行二次学习，以弥补文本图卷积节点特征利用不足的问题，提升单标签文本分类的准确率以及整个模型泛化能力。为了降低集成学习的时间消耗，移除了集成学习中的k折交叉验证机制，融合算法实现了文本图卷积和Stacking集成学习方法的关联。在R8、R52、MR、Ohsumed、20NG等数据集上的分类效果相对于传统的分类模型分别提升了1.5%、2.5%、11%、12%、7%以上，该方法在同领域的分类算法比较中表现优异。

大数据时代，网络文本数据日益增长，数据量越来越庞大，科学管理和组织这些数据变得尤其重要，因此许多文本处理方法[1]应运而生。文本分类是自然语言处理中非常重要的研究领域之一，大量的应用使用了文本分类技术，如垃圾邮件检测、新闻过滤、计算表型、观点挖掘、情感分析和文档的组织[1,2]等。

文本分类方法可分为传统方法和深度方法。传统文本分类方法主要采用的是机器学习方法，对文本的表示及分类进行研究。传统的文本特征提取方法如n-gram法，得到文本的表示不够充分，缺少文本的词序关系[2],这使得文本的表示受到限制，处理方式也不够灵活，且在分类方面只是采用单个分类器进行分类，分类精度不高。深度学习的文本表示方法，如利用卷积神经网络(CNN)[3]和基于BiLSTM[4]的循环神经网络(RNN)[5]学习局部连续的单词序列对文本进行表示学习，使文本的表示更加灵活，提升了文本分类的效果。然而这类文本表示方法无法获取句子的语法结构信息以及全局信息，使得分类效果受到限制。另外，CNN和RNN等深度学习模型受限于欧氏结构数据，对于文本这类原本就属于非欧氏结构的数据来说则需要做更多的处理。随着深度学习的进一步发展，图神经网络的研究得到越来越多的关注。研究人员发现，图神网络非常适合文本这类非欧氏结构数据的处理[6],如文本图卷积模型[7],能够在训练中自动学习单词和文档的嵌入；并且图神经网络能够整合文本的结构信息，提升文本的表征能力。然而在最终的分类方面，图神经网络模型并没有充分利用神经网络学习到的特征。为了解决以上问题并提升文本分类的效果，本文提出了新的文本分类模型TGCN-S(text GCN-Stacking),通过使用Stacking集成学习方法，对文本图卷积得到的特征进行拟合训练，解决文本图卷积特征利用不足的问题，提高了分类效果和模型的泛化能力；为了提高集成学习的速度，移除了集成学习中的交叉验证机制。该模型的有效性在R8、R52、MR、Ohsumed和20NG等数据集的实验上得到验证。

综上所述，本文提出了新的文本分类模型TGCN-S,主要贡献和创新点概括如下：a)本文利用文本图卷积获取文本的全局信息和文本的结构信息，解决传统模型无法获取文本的结构信息的问题，提升文本的特征表达；b)优化Stacking集成学习模块，移除k折交叉验证，在保证分类效率的同时降低Stacking学习过程的时间消耗，将softmax分类器替换为Stacking集成学习分类器，有效地解决了文本图卷积特征利用不充分的问题，提升了整个模型的分类效果和泛化能力；c)融合文本图卷积和集成学习的优点，提出新的文本分类模型TGCN-S,提高文本分类的准确率。

1 相关工作
1.1 传统的文本分类
传统的文本分类方法有很多，如支持向量机(SVM)[2]、K最近邻(KNN)和随机森林(RF)[1]等，这些文本分类方法主要聚焦于文本的表示以及相应算法的研究，例如词袋法和n-grams表示法。词袋法将文档划分为一个单词集合，并确定它们在文档中出现的频率；n-gram法[8]将文本中连续的n个词语作为一个对象，再将所有的对象放在一起形成一个集合。词袋法中，文本的最终表示结果与集合中单词顺序无关[2],这将导致句子语法特性以及单词间的相关性丢失，使得文本表示不够充分，无法得到文本全局信息；相比于词袋法，n-gram能够得到单词的相关性，但忽略了句子的句法特性，对文本的表示不够充分且缺乏灵活性，同样地，使得文本的全局信息丢失。

1.2 基于深度学习的文本分类
目前，大多数的文本分类方法是基于深度学习的，其中具有代表性的如应用于语句分类的CNN[3]、基于双向长短期记忆BiLSTM[4]的RNN以及BERT模型[9]等。Kim[3]于2014年提出了基于CNN的语句分类，它将一维卷积应用在文本语句上，在分类准确度上取得了比较好的结果。Liu等人[5]通过将LSTM应用在文本分类中，以学习文本表示，保留文本更长的单词信息，提高了文本的表达能力。Devlin等人[9]提出了BERT模型，是一种预训练语言的文本表示模型，在大量文本语料中训练了一个通用的语言表示模型，能够捕获单词间更长的依赖。这些模型的出现很大程度上解决了传统分类方法文本表征不足的问题，但是没有捕获文本的结构信息和全局信息。CNN与RNN都主要是针对局部连续的单词序列，能够很好地捕获文本中的局部信息，但无法得到语料库中单词的全局共现信息以及文本的结构信息。并且以上模型都局限于欧氏结构数据的学习，对于非欧氏结构数据的处理则会显得捉襟见肘，例如文本数据，如果不进行特殊处理，很难捕获文本的结构信息。

随着深度学习技术的发展，图神经网络的研究得到越来越多的关注。GNN不仅具有参数共享、降低计算量的优点，而且非常适合文本中单词之间非欧氏结构数据的处理，取得了机器学习领域的突破；GNN还能够提取多尺度的局部空间特征并抽象组合成高层特征，通过图嵌入，GNN能够学习图的节点、边以及子图的低维度向量表示[8],突破了一般机器学习需要依赖手工的网络结构设计问题，提高了学习的灵活性。Cai等人[8]证明了图神经网络能够很好地处理具有丰富关系的结构任务能够在图嵌入的过程中保留图的全局信息；Kipf等人[10]对图神经网络进行了简化，提出了一种图卷积神经网络模型GCN,该模型可以捕获高阶邻域特征，提升文本分类的准确率；Yao等人[7]将GCN运用到文本分类中并提出了Text GCN模型，对语料库构建大型的异构图，以句子和单词作为图中的节点，通过GCN学习单词和句子嵌入，获取文本中单词的全局信息以及整个文本的结构信息，最后得到文本的特征。

1.3 分类器
目前，不管是传统的文本分类还是基于深度学习的文本分类方法，在提取文本的特征后，使用单一的分类器进行分类，如使用softmax得到每个类别的概率，并选择概率最大分类作为文本最终的分类。单一的分类器直接进行分类使得分类结果一次就确定下来，在出现分类失误的情况下，无法对分类结果进行修正调整。集成学习是由多个弱分类器组成的一个强分类器，可以作为一个整体的分类器用于分类，能够很好地解决单个分类器分类能力不足的问题[11]。集成学习可以分为Boosting算法、Bagging算法以及Stacking算法[12]三类。其中具有代表性的是Stacking算法，在灵活性和扩展性方面，Stacking算法比其他两个算法都要好[13,14],更具效率优势。Stacking模型能够灵活高效地对文本进行分类，然而，其分类效果依赖于传入Stacking模型的文本特征。基于以上问题，本文提出了一种融合文本图卷积和Stacking集成学习的文本分类方法TGCN-S,利用文本图卷积提取文本特征，通过集成学习弥补原图卷积特征利用不足的问题，提升文本分类的准确性以及模型的泛化能力。为了降低集成学习的拟合时间，移除了Stacking集成学习中的交叉验证机制，以提升集成学习部分的拟合速度。

2 TGCN-S算法
本文通过融合文本图卷积和Stacking集成学习方法提出了一种新的文本分类算法TGCN-S,结合了文本图卷积和Stacking的优点，解决了文本图卷积特征利用不足的问题，提高了文本分类准确度和模型的泛化能力。为了降低集成学习部分的时间消耗，移除了Stacking集成学习中的交叉验证机制以提升集成学习的拟合速度，提高文本分类的效率。

2.1 TGCN-S模型结构
本文提出的TGCN-S模型如图1所示，将模型分为特征提取和Stacking集成分类两部分。TGCN-S由Text GCN和Stacking两个部分连接而成，将Text GCN提取的特征作为Stacking集成学习的输入，并将Text GCN分类结果与Stacking第一层分类结果拼接作为Stacking第二层的输入，形成残差连接。这种跳跃式连接的方式提升了两个模型之间的关联，增强了Stacking第二层输入的特征表达。最终通过Stacking的第二部分进行分类，得到文本最后的分类结果。在图1中，文本异构图的黑点表示文档，白点表示单词，实线表示文档与单词的联系，虚线表示单词之间的联系，根据文本异构图计算得到的邻接矩阵作为Text GCN的输入。

图1 TGCN-S总体流程
图1 TGCN-S总体流程   下载原图

Fig. 1 TGCN-S overall flowchart

2.2 特征提取
本文主要使用Text GCN作为特征提取器，作为整个模型的第一部分。在对文本进行构图的过程中，将单词和文档作为图的节点，单词与文档之间的连接权值用词频逆文档频率(TF-IDF)表示，单词与单词之间的连接权值使用逐点互信息(PMI)表示。PMI的计算方式如下：

PMI(i,j)=logP(i,j)P(i)×P(j),P(i,j)=N(i,j)N,P(i)=N(i)N (1)

其中：N是滑动窗口总数；N(i,j)表示同时包含节点i、j的滑动窗口数；N(i)表示包含节点i的滑动窗口数；P(i,j)表示同时包含节点i、j的概率；P(i)表示滑动窗口包含节点i的概率。由此得到节点i、j之间边的权重Aij,定义如下：

 
其中：w表示单词；doc表示一个文档。当PMI为正值时，表示语料库中单词的语义相关性较高；当PMI为负值时，表示语料库中单词的语义相关性很低或者没有。在构建异构图时，只在PMI为正值的节点对直接添加边；之后再将带权图输入到一个简单的两层GCN进行学习。在GCN第二层得到词文档嵌入，嵌入的维度与标签类别数大小相同。提取的特征Z可以用式(3)计算。最后将节点的嵌入送到softmax函数中，得到临时的分类输出Y,如式(4)所示。

Z=A ˆReLU(A ˆXW0)W1 (3)

Y=softmax(Z) (4)

其中：A ˆ=D ˆ−12A ˆD ˆ−12,而A ˆ=A+IN;A是n阶邻接矩阵；IN是n阶单位矩阵，n是顶点个数；D ˆ是A ˆ对应的度矩阵，其中D ˆij=∑jA ˆij;X是由n个节点的特征构成的特征矩阵；W0、W1分别是特定于第一层和第二层的可训练的权重矩阵；ReLU是层间的激活函数。

2.3 集成学习部分
TGCN-S的第二个部分就是Stacking集成学习，传统的Stacking集成模型如图2所示。传统的Stacking集成学习模型(图2)对多个基分类器(Ck,(k=1,2,…,m))进行训练，然后将多个训练好的基分类器对训练集中的数据进行预测得到训练集的预测值Pi(i=1,2,…,m),再对测试集中的数据进行预测得到测试集对应的预测值pj(j=1,2,…,m),最后将多个基分类器得到的预测结果组合在一起拼接成新数据集，各个基分类器对同一个样本的预测结果组合在一起作为该样本的新特征，训练集得到的预测值组合在一起作为新的训练集特征(P1,P2,…,Pm),测试集得到的预测值组合在一起形成新的测试集特征(p1,p2,…,pm);然后将得到的两组特征集通过Stacking第二层融合分类器进行训练和预测，得到最后的分类。

图2 Stacking 集成学习系统
图2 Stacking 集成学习系统   下载原图

Fig. 2 Stacking integrated learning system

一般地，Text GCN直接利用softmax对GCN中得到的特征进行分类，并以此作为最终输出，其对训练的特征并没有很好地利用。TGCN-S模型融合了Stacking集成分类以及Text GCN优点，在使用softmax对GCN中得到的特征进行分类的过程中，还利用Stacking集成学习中各基分类器对GCN学习到的特征进行二次拟合，最后进行融合分类，获得文本最终分类结果。

与传统的Stacking集成学习不同，TGCN-S中Stacking集成学习部分包含基分类层和融合层。第一层基分类层由五个基分类器组成，第二层融合层除了直接使用各基分类器的分类结果和数据，还整合了Text GCN分类的输出结果和数据，即特征提取过程中的训练和预测结果Y(式(4)),形成跳跃式连接。这种跳跃式连接不仅增强了文本图卷积和Staking集成模型之间的联系，而且将Text GCN预测效果代入Stacking第二层，提升了融合层的分类效果。为了降低集成学习部分的时间消耗，去除Stacking的交叉验证机制以提高模型的拟合速度。模型的特征组合过程如图3所示，其中Ci (i=1,2,3,4,5)为基分类器，Tri为基分类器得到的训练结果，Tei (i=1,2,3,4,5)为基分类器的预测结果，train_set是由各个Tri组成的训练集，test_set是由各个Tei组成的测试集。

图3 新特征组合过程示意图
图3 新特征组合过程示意图   下载原图

Fig. 3 Schematic of the new feature combination process

Stacking第一层是由多个基分类器组成，对于基分类器的选择，主要遵循的原则是“各个基分类器准而不同”,不同的基分类器之间要有所差异[12]。本文Stacking集成学习的基分类层采用了五种基分类器：支持向量机(SVM)、决策树(DT)、随机森林(RF)、K最近邻(KNN)以及高斯朴素贝叶斯(Gaussian NB)。一般认为，这五种分类器具有基础性的作用，其他大多数分类方法基本上都是基于这五种分类器中的某一个或多个进行改进优化的。另外随着模型复杂性和模型数量的增加，模型整体训练的时间必然增加，模型训练拟合开销也会随之增加。基于以上考虑，TGCN-S模型Stacking第一层的基分类器以上述五种为主；第二层分类器在单个机器学习分类器预测的基础上采用投票法给出最终分类结果。

3 实验结果和分析
3.1 数据集
主要使用R8、Ohsumed、MR、R52和20NG五个数据集对本文TGCN-S模型进行实验对比，分析TGCN-S的分类效果。

a)R8数据集。该数据集分离自路透社语料库，只有八个类别，其中有5 485个训练文档和2 189个测试文档。

b)Ohsumed数据集。它是由国家医学图书馆维护的重要的医学文献数目的数据库。提取其中只有单一分类的数据，构成本实验的训练测试用例，其中3 357个文档用于训练，4 043个文档用于测试，总共7 400个数据。

c)MR数据集。MR是一个电影评论数据集，每个评论只包含一句话，其中有5 331篇正面评论，5 331篇负面评论。

d)R52数据集。它也是分离自路透社语料库，有52个类别，有6 532个训练数据和2 568个测试数据。

e)20NG。它是一个含有20个类别的新闻组数据集，训练集有11 314个文档，测试集有7 532个文档。

这些数据由于是文本数据，并不能直接用于模型的训练，需要对其进行预处理[7]。通过预处理，得到表1的统计信息，从中可以看到每个数据集的训练集和测试集的大小。

表1 各个数据集的统计信息 导出到EXCEL

Tab. 1 Statistics for each dataset


数据集	docs	training	test	words	nodes	classes

R8	7 674	5 485	2 189	7 688	15 362	8

R52	9 100	6 532	2 568	8 892	17 992	52

Ohsumed	7 400	3 357	4 043	14 157	21 557	23

MR	10 662	7 108	3 554	18 764	29 426	2

20NG	18 846	11 314	7 532	42 757	61 603	20
3.2 对比模型实验数据
1)CNN 针对文本分类的卷积神经网络，由Kim[3]于2014年提出，通过在预训练的词向量之上训练的卷积神经网络进行句子级的分类任务。

2)LSTM 由Liu等人[5]于2016年提出的基于长短期记忆文本分类模型，通过使用最后一个隐藏状态作为整个文本的表示形式。

3)Bi-LSTM 双向长短期记忆文本分类模型，是LSTM的改版，以预训练的词嵌入作为Bi-LSTM[4]的输入。

4)FastText 由Joulin等人[15]于2017年提出的简单有效的文本分类模型，通过将单词n-gram嵌入的平均值作为文档的嵌入，再将得到的文档嵌入送入线性分类器进行分类。

5)Text GCN 由Yao等人[7]于2019年提出的基于图卷积的文本分类方法，该方法基于单词共现和文档单词关系为整个语料库构建大型异构文本图，再使用图卷积神经网络和softmax进行学习分类。

通过本文模型与上述几个模型的实验对比得到不同模型在不同数据集上的准确率，结果如表2所示。

表2 数据集在各个模型上的预测准确率 导出到EXCEL

Tab. 2 Prediction accuracy of datasets on each model


模型	R8	R52	Ohsumed	MR	20NG

CNN	0.940 2	0.853 7	0.439 7	0.749 8	0.769 3

LSTM	0.936 8	0.855 4	0.411 3	0.750 6	0.657 1

Bi-LSTM	0.963 1	0.905 4	0.492 7	0.776 8	0.731 8

FastText	0.961 3	0.928 1	0.577 0	0.751 4	0.796 7

Text GCN	0.970 7	0.935 6	0.683 6	0.767 4	0.863 4

TGCN-S-vote	0.985 8	0.960 4	0.809 0	0.882 8	0.930 2
如表2所示，本文提出的TGCN-S在五个数据集上的测试精度都表现得最好，且有着不同程度的提升。针对R8数据集，TGCN-S的表现比其中最好的Text GCN高出了1.5个百分点，比其他文本分类算法的精度高出了至少2个百分点[7];对于R52数据集，本文模型比其他模型高出了2.5个百分点以上，相比于CNN模型，分类效果提高了13个百分点；在Ohsumed数据集，TGCN-S的表现比Text GCN模型的表现高出了12个百分点，比其他分类模型高出了20个百分点以上[7];对于MR数据集，TGCN-S模型在测试精度上比Text GCN模型高出了接近11个百分点[7],比其他模型都高出了接近14个百分点[7];在20NG这种较大数据集上，TGCN-S也比TextGCN模型高出7个百分点，比其他模型高出12个百分点以上。图4直观地展示了各个模型在所用数据集的预测结果。从图4可以看出，本文模型的分类效果都优于对比模型。图上的数据充分说明，Stacking集成学习能够对文本图卷积学习到的文本特征进行更高效的利用，能够在不同程度上提升分类效果。从表2的数据中可以发现，本文模型对不同的数据集的分类效果有着不同的提升，但对于Ohsumed和MR两个数据集的分类效果没有其他数据集的结果好，原因在于MR数据中存在多个极性评论，如“这部电影故事很丰富，但是太恐怖了”;同样地，在Ohsumed数据集中各种医学文献之间的描述是相互关联的，在描述某种病例时会提及与病例有关的药物和信息。图神经网络虽然能捕获文本全局信息，但是无法获取文本内的词序特征，以至于无法提取文本的详细特征，进而导致分类效果欠佳。即便如此，本文方法相对于其他单个分类器来说仍有非常大的提升。这也说明融合Stacking集成学习后的模型，通过投票机制能够有效地提高文本分类的效果，即便文本中存在多极性的描述，也能得到较高的准确率。这些实验数据也证明了本文模型的有效性，可以在很大程度上提升文本分类的准确率。

图4 模型预测结果直方图
图4 模型预测结果直方图   下载原图

Fig. 4 Prediction histogram of models

单一的准确率并不能很好地确定模型的质量，为此，本文采用对比各个模型的宏观F1(macro-F1)和微观F1(micro-F1)来评估模型的性能，它们是综合考虑了模型的查准率和查全率的计算结果，macro-F1与micro-F1的值越大，说明模型的质量越高、分类性能越好。文献[4]指出，Text GCN的模型分类效果和模型质量都优于CNN、LSTM、BiLSTM、FastText等，因此，本文主要对Text GCN与TGCN-S-vote模型的macro-F1与micro-F1值进行比较，以对比判断本文模型TCGN-S-vote的性能。各个数据集在两个模型的macro-F1与micro-F1值如表3所示。由表3可以看出，本文模型总体上的macro-F1与micro-F1的得分都比Text GCN模型的要高，说明本文模型相比于Text GCN模型的质量更高，模型的分类效果也更好。为了对比模型的收敛情况，将Text GCN与本文模型进行比较，通过每个epoch的准确率以及达到稳定时的状态来确定模型的收敛能力，实验结果用折线统计图来表示。图5分别画出了MR、R52、R8数据集在Text GCN和TGCN-S-vote模型的各个epoch的准确率。从图中可以看到，本文模型在各个数据集上的收敛速度都比Text GCN要快，都能更早地达到稳定状态。同时从分类准确率的角度来看，本文模型最终的分类准确率都比Text GCN要高。

表3 各数据集在Text GCN与TGCN-S-vote上的F1得分 导出到EXCEL

Tab. 3 F1 score for each dataset on Text GCN and TGCN-S-vote


评估标准	模型	R8	R52	Ohsumed	MR	20NG

micro-F1	Text GCN	0.969	0.588	0.674	0.813	0.858

TGCN-S-vote	0.977	0.831	0.781	0.876	0.930

macro-F1	Text GCN	0.933	0.711	0.683	0.758	0.853

TGCN-S-vote	0.945	0.960	0.792	0.879	0.937
3.3 去交叉验证的集成学习
为了简化集成学习模块、提高整个模型的训练预测速度，去除了Stacking中所有基分类器的交叉验证机制，只通过随机打乱的方式对训练集和测试集进行处理，并在各个数据集上进行了对比实验。实验结果如表4所示。

表4 去交叉验证对比数据 导出到EXCEL

Tab. 4 Comparison data with removed cross-checks


方法	R8	R52	Ohsumed	MR	20NG

Kfoldt	31.64	225.54	61.02	27.73	253.32

nKfoldt	11.21	76.10	33.26	5.26	100.26

KP	0.983 1	0.953 8	0.835 7	0.875 8	0.923 3

nKP	0.985 8	0.960 4	0.842 9	0.882 8	0.933 4
表4中，Kfoldt和KP分别表示使用k折交叉验证Stacking模型所花费的时间及分类准确率，nKfoldt和nKP分别表示未使用k折交叉验证Stacking部分的耗时及对应的分类准确率。从表4中可以发现，不使用k折交叉验证的时间消耗低于使用k折交叉验证的时间消耗，因为在Stacking部分少了k-1次的模型的拟合，所以时间有所减少。并且不使用k折交叉验证的分类准确率也表现出不低于使用k折交叉验证的分类准确率。这是因为，k折交叉验证原本用于数据集较少的情况，以提高模型的泛化能力，对于数据集较多的情况，进行交叉验证的效果收益甚微，还会影响模型的拟合速度，本实验的数据集就是如此。因此，本文模型去除了Stacking集成学习交叉验证机制，以降低模型的时间花费，提升模型训练预测速度的同时保持良好的分类准确率。

图5 训练周期与准确率的折线图
图5 训练周期与准确率的折线图   下载原图

Fig. 5 Line chart of training cycle and accuracy

3.4 集成学习融合层的对比实验
为了分析Stacking模型中第二层融合分类器Vote对最终模型分类效果的影响，本实验通过选择九种常用机器学习方法作为Stacking第二层的融合分类法，并分别在R8、R52、Ohsumed、MR以及20NG这五个数据集进行对比实验。九种分类器如下：高斯贝叶斯分类器(GaussianNB)、线性回归(Linear-Regression)、逻辑回归(LogisticRegression)、决策树(DecisionTree)、LightGBM[16]、支持向量机(SVM)、AdaBoost[17]、Bagging[18]以及Voting投票法。实验结果如表5所示。从表5中可以看出，使用不同的分类方法作为融合层的分类器会有不同的分类效果。在这五个数据集中，除了在Ohsumed数据集上以LightGBM作为融合分类器的测试精度略大于投票法之外，其他数据集中投票法的测试精度都优于其他分类器。这体现了投票法的通用性，且投票法思想简单、易于实现。因此本文模型以投票法作为Stacking模型第二层的融合分类器。

表5 融合分类器在五个数据集上的表现 导出到EXCEL

Tab. 5 Performance of each fused classifier on 5 datasets


融合分类器	R8	R52	Ohsumed	MR	20NG

GaussianNB	0.968 9	0.953 7	0.705 7	0.878 6	0.753 8

LinearRegression	0.978 3	0.953 7	0.728 9	0.757 4	0.819 2

LogisticRegression	0.961 6	0.773 6	0.383 4	0.867 3	0.406 7

DecisionTree	0.972 6	0.956 9	0.768 2	0.863 2	0.854 7

LightGBM	0.983 6	0.090 1	0.821 7	0.858 4	0.773 8

SVM	0.967 1	0.876 3	0.674 7	0.834 7	0.756 3

AdaBoost	0.930 6	0.800 0	0.495 7	0.873 6	0.360 4

Bagging	0.982 6	0.953 2	0.782 3	0.878 8	0.832 0

Voteing	0.985 8	0.960 4	0.809 0	0.882 8	0.930 2
4 结束语
本文提出了一种融合文本图卷积和Stacking集成学习的文本分类方法(TGCN-S),以解决Text GCN特征利用不足的问题，提高文本分类准确率。不同于传统方法使用单个分类器对文本分类或者深度学习使用softmax直接对Text GCN提取的特征进行分类，TGCN-S采用Stacking集成学习，对Text GCN得到的特征进行二次学习，同时，去除Stacking集成学习中基分类器的交叉验证机制，加速模型拟合，最后通过融合层得到样本最后的分类。本文TGCN-S模型在R8、R52、MR、Ohsumed以及20NG等数据集上的准确率分别达到了98.58%、96.04%、88.28%、80.90%、93.02%,相对于其他模型有着很大的提升。实验结果表明，本文模型在文本分类方面具有较高的识别效果，同时也证明了本文方法的可行性。

本文对于Stacking的基分类器参数只是凭借经验设置，并没有对这些参数进行优化，未来研究方向可以对这些基分类器的参数进行优化，以进一步提高整个模型的分类效果，提高模型的分类精度。同时图卷积学习到的特征表达缺少语句中的词序关系，因此丰富文本的特征表达也是未来研究方向之一。

摘 要：近年来恶意软件不断地发展变化，导致单一检测模型的准确率较低，使用集成学习组合多种模型可
以提高检测效果，但集成模型中基学习器的准确性和多样性难以平衡。因此提出一种基于遗传规划的集成模
型生成方法，遗传规划可以将特征处理和构建集成模型两个阶段集成到单个程序树中，解决了传统的恶意软
件集成检测模型难以平衡个体准确率和多样性的问题。该方法以集成模型的恶意软件检出率作为种群进化依
据，保证了基学习器准确性。在构建集成模型时自动选择特征处理方法、分类算法和优化基学习器的超参数，
通过输入属性扰动和算法参数扰动增加基学习器的多样性，根据“优胜劣汰”的思想，进化生成具有高准确
性和多样性的最优集成模型。在 EMBER 数据集上验证，结果表明，最优集成模型的检测准确率达到 98.88%。
进一步的分析表明，该方法生成的模型具有较高的多样性和可解释性。

0 引言
恶意软件是当今互联网上最大的安全隐患之一，AVTEST 的统计数据显示，2021 年已发现的恶意软件数量已经
达到约 13.03 亿，且仍在 增加。 国家 互联网 应急中 心
(CNCERT)发表的《2021 年上半年我国互联网网络安全监测
数据分析报告》指出，2021 年上半年，捕获恶意程序样本
约 2307 万个，日均传播次数达到 582 万次。因此，对恶意软件的检测一直是网络空间安全的重要课题之一。
传统的恶意软件检测技术包括基于签名的检测方法和基
于启发式的方法，这些方法需要专家分析恶意软件提取签名
或制定规则进行检测，然而代码混淆和加壳等技术的出现，
使恶意软件可以逃脱传统的检测技术，导致检测效率较低且
难以识别。此外，恶意软件开发人员可以通过自动化恶意软
件开发包创建数千个恶意代码，恶意代码数量剧增。使用人
工分析恶意软件的难度越来越高。随着人工智能的发展，恶意软件检测技术开始和人工智能结合，以提高恶意软件的检
测能力。
近年来，机器学习[1~4]、深度学习[5~8]及集成学习[9~11]的
方法开始被应用到恶意软件检测与分类。相比于传统的恶意
软件检测技术，许多机器学习和深度学习方法极大地提高了
恶意软件检测的准确率。但是由于恶意软件的不断发展变化，
造成单模型的误报率、漏检率过高的问题。因此集成学习也
被广泛应用于恶意软件检测方面，利用多个学习器组成集成
学习模型以提高恶意软件检测的准确性。例如，Guo Hui 等
人[10]将二进制数据转换为灰度图像，提取图像的 GIST 纹理
特征以K近邻和随机森林方法作为基学习器，采用投票方法
获得最终的恶意软件分类结果，通过集成学习有效提高了恶
意软件的分类效果。在文献[11]中将全连接多层感知机和一
维卷积神经网络作为基学习器，获得每个基学习器的预测结
果，构成新的特征矩阵，使用该特征矩阵训练极限树，并作
为元学习器，从而提高了恶意软件检测的准确性。上述研究
表明，多个学习器集成可以进一步提高模型的检测能力。但
是，集成检测模型的学习效果与基学习器的多样性和准确性
息息相关。因此，如何在构建集成模型时保证其多样性和准
确性仍然是当前研究难点。
目前基于集成学习的恶意软件检测方案大致可以划分成
恶意软件特征提取、特征处理、设计集成模型三个主要步骤。
在特征提取阶段，从软件中提取一种或多种特征，如字节序
列特征、文件头部信息等；之后在特征处理阶段，采用多种
特征处理方法，从原始特征中学习更具分辨力的高级特征，
如基于遗传编程的特征筛选[12]、信息增益等方法；在设计
集成模型阶段，集成模型一般可分为两层，第一层是模型选
择，即选择一种或多种分类算法作为基学习。第二层则是基
学习器通过投票法、平均法等集成策略获得最终预测结果，
或将基学习器的输出通过集成策略作为新的特征 ， 如
Stacking、Blending 等，输入到元学习器中获得最终预测结
果。目前大多数研究中这三个步骤是独立进行的，所有基学
习器的输入特征一样，没有考虑不同特征组合对基学习器的
影响，并存在特征冗余问题，导致基学习器的准确性较低，
集成结果不理想。另外，在设计集成模型时，大多数集成学
习模型都依赖于人工经验选择基学习器，存在集成模型多样
性差的问题。此外，新的恶意软件在不断地出现和发展，一
种分类算法很难有效的检测出所有恶意软件。所以利用集成
学习来增强检测模型的准确性是目前最为有效的方法之一。
如何在保证基学习器准确率的基础上，增加基学习器的多样
性，产生更好的集成结果，仍是一个具有挑战性的问题。
遗传规划(Genetic programming，简称 GP)是由生物进化
启发而来的一种进化计算技术，具有优秀的搜索能力，可以
从终端集、功能集中选择叶子节点及内部节点生成多个解决
方案，通过种群进化生成解决特定问题的最优解决方案[12]。
在分类问题中，GP 可以通过对训练集多次学习，在学习过
程中来进化分类器。常用的基于 GP 的分类器通常将特征作
为输入，输出一个浮点数，根据预定义的阈值对分类任务进
行决策。因此可以先通过 GP 生成集成学习中的基学习器，
之后利用现有的集成方法如 bagging 和 boosting 构建基于 GP
的分类器集成，保证集成学习中多样性和准确性，提高集成
模型的性能。Karakatič 和 Podgorelec[13]开发了一种用于分类
的方法，将 AdaBoost 和基于 GP 的分类器结合以提高模型
性能，其中 AdaBoost 用于更新集成中的实例和每个基于 GP
的分类器的权重。Zhang,T[14]等人提出了 EGPEL 方法用于人脸识别，该方法自动构建集成学习模型，从而提高单个基学
习器在人脸图像数据集上的性能。文献[15]中提出一种基于
GP 的特征构造集成分类方法。该方法将预提取的纹理、颜
色、频率、局部和全局特征作为 GP 框架中分类器的输入，
最终构建类间区分明显的特征和生成诊断结果更准确的集成
模型。现有工作表明，基于 GP 生成的集成模型在分类任务
上取得了较好的结果。但是，在恶意软件检测时，由于不同
的任务在进行特征提取的需求和难度不同，大多数基于 GP
生成集成模型的方法不能直接用于处理恶意软件检测任务。
此外，在恶意软件检测方面，遗传规划大多被用在特征
处理阶段，获得最佳特征组合。如文献[16]设计了一种基于
遗传规划的特征选择方法，与基于 Filter 的特征选择方法相
比，该方法减小了机器学习模型的计算量，但是准确率不如
基于集成学习的检测方法。因此，可以通过 GP 灵活的基于
树的表示，将特征处理和设计集成学习模型两个阶段集成到
单个 GP 树中，从而自动从原始样本特征演化出有效的识别
恶意软件解决方案。然而，现有的基于 GP 生成集成模型的
方法无法实现这一点。
本文的总体目标是开发一种新的有效的基于 GP 的恶意
软件集成检测模型生成方法(A Genetic Programming-Based
Malware Integrated Detection Model Generation Method ，
GPMD)，该方法自动学习原始特征和进化生成集成模型，
保证基学习器的准确性和多样性。为了实现这一目标，设计
了一个新的集成模型结构作为遗传规划中个体的表示。把特
征处理相关操作、分类算法作为功能集，原始特征、分类算
法相关参数等作为终端集，GPMD自动进化它们的组合以形
成解决方案。每个解决方案都会为输入样本生成类别标签的
组合预测。最终，在进化过程中演化出具有高准确率和多样
性的最优集成检测模型。此外，该模型具有较高的可解释性，
可以清晰的看到集成学习模型中每个基学习器所使用的特征
组合，如何对原始特征进行处理。本文主要工作为
a) 提出了一种基于遗传规划的集成检测模型生成方法
GPMD。该方法在生成集成模型时可以自动选择特征处理方
法、分类算法和优化基学习器的超参数，通过输入属性扰动
和算法参数扰动保证基学习器的多样性。将恶意软件的检出
率作为 GPMD 中个体的进化依据，保证基学习器的准确性。
b) 设计了一个新的集成模型结构，该结构包含输入层、
特征图像化层、图像加权融合层、特征学习层，特征融合层，
基学习器选择层、集成层、和输出层，具有较高的可解释性。
c) 提出了一组适用于恶意软件检测的功能集和终端集，
用于生成集成检测模型。
本文提取了 Ember 数据集中样本的四种不同类型的特征，
包括字节统计值(histogram，简称 his)、字节熵(byteentropy，
简称 byte)、导入函数调用信息(imports，简称 imp)和区段信
息(section，简称 sec)，作为 GPMD 种群中每个个体的输入。
本文所提方法的包含两个模块，各个模块的功能和总体流程
如下。
a) GPMD 最优集成模型生成模块：该模块用于生成最优
集成模型。GPMD并不能直接对恶意软件进行检测，而是在
预定义的功能集、终端集中选择不同的叶子节点和内部节点，
采用混合法(ramped half-and-half)构造出多个集成模型[18]，
组成初始化种群。之后对每个集成模型进行适应度评估，通
过遗传操作算子产生的下一代种群，通过一代又一代的进化，获得最优集成检测模型。
b) 最优集成模型训练及测试模块：该模块分为两个阶
段。在训练阶段，将训练集放入最优集成模型中，训练并保
存模型。测试阶段则利用已经训练好的检测模型进行检测并
输出检测结果。
2 方法实现
设计生成恶意软件检测模型的 GP 算法时，需要考虑初
始化种群时所需的功能集、终端集；用于评价模型好坏的适
应度函数；种群中的个体表示(即集成模型结构)；终止条件
以及 GP 参数五个基本要素。在本文中终止条件设为达到遗
传代数，GP 参数将在 3.3 节进行详细阐述。因此本章将分
GPMD方法描述、个体表示与最优集成模型、功能集、终端
集四个重要部分进行介绍。
2.1 GPMD 方法描述
GPMD 方法的流程图如图 1 中模型生成过程所示，首先，
将原始特征进行标准化处理，从终端集、功能集中选择叶子
节点及内部节点生成多个集成模型，并组成初代种群。之后
随机抽取样本输入到每个集成模型，加快种群中每个模型的
收敛速度，计算种群中每个集成模型的适应度值，并将集成
模型及适应度值记录到缓存表中，在进行下一代适应度评估
时，如果下一代的集成模型在缓存表中，将适应值直接赋值
给该模型，减少遗传规划在生成最优集成模型时的计算开销。
随后判断是否达到种群迭代次数，若没有，则将种群中适应
度值高的。
个体通过精英保留策略复制到下一代种群，避免最优个
体丢失。通过锦标赛选择算子从当前种群选取父代集成模型，
在一定概率下，父代集成模型发生子树交叉、子树变异形成
下一代新种群，重复上述操作，直到达到迭代次数，输出最
优集成模型。GPMD 具体算法描述如算法 1 所示。算法 1 GPMD 最优模型生成算法
输入：字节直方图(his)、字节熵直方图(byte)、导入函数(imp)和
区段信息(sec)，遗传代数 G，当前代数 g，精英保留概率 E，种群
数量 p。
输出：最优集成检测模型。
a) 样本中每个特征值/该样本的总字节数，标准化 his；
采用最大最小归一化，标准化处理 byte、imp、sec。
b) 使用 genHalfAndHalfMD()从功能集和终端集中选择节点，
生成 p 个集成模型，作为初始种群 P0；
c) 创建记录表 R，精英表 BP；
计算 P0 中每个集成模型的适应度值，存入 R。使用无放回抽样的方法抽取 1000 个样本标准化后的原始特征作
为当代种群的输入；
 if not BP：// 判断精英表是否为 null
 清空 BP;
根据精英保留策略，复制种群 Pg 中适应度值排名前 E*p 的个体及
其适应度值，存入 BP；
通过锦标赛选择算子从 Pg 选择集成模型个体作为父系 F；
从 F 中选择集成模型进行子树交叉、子树变异操作生成子代 Og+1；
 for 每个集成模型 o in Og+1：
 if o not in R：
 使用适应度函数 Fitness(I)计算适应度值；
 将集成模型 o 及其适应度值存入 R；
 else：
 将 R 中的适应度值赋值给 o 的适应度值；
 BI 与 Og+1 合并获得下一代种群 Pg+1；
 g=g+1。
e) 输出 BP 中适应度最高的个体。
适应度函数负责评价种群中每个集成模型的好坏，确定
种群的进化方向以及寻找最优集成模型。针对恶意软件检测
而言，恶意软件的检出率是最重要的一个指标，因此 GPMD
的适应度函数如式(1)所示。采用 K 折交叉验证法评估每个
模型性能，每个集成模型将 K(K=5)折交叉验证的平均结果
作为该模型的适应度值。
F Mal num Mal all itness _ / _ =
(1)
其中 Mal_num 表示集成模型检测出的恶意软件数量，
Mal_all 表示样本中恶意软件总数。
2.2 个体表示及最优集成模型
每个个体包含特征处理和构建集成模型两个阶段，为此
设计了一个新的集成检测模型结构作为个体表示，如图 2 所
示。该集成模型结构包括原始特征输入层、特征图像化层、
图像加权融合层、图像特征学习层，特征融合层，基学习器
选择层、集成层、和检测结果输出层。除了输入层和输出层，
每一层都有不同的函数，实现对应的功能。输入层代表集成
模型的输入，输入层的数据由终端集提供，具体内容将在
2.4 节详细阐述。恶意软件的特征处理阶段包含四层，首先
将原始特征转换为灰度图像的特征图像化层，其次图像加权
融合层将多张灰度特征图融合为一张图像，之后通过特征学
习层提取多种图像特征，最后在特征融合层将多种图像特征
连接形成高级特征向量。经过特征处理后的特征向量输入基
学习器，获得基学习器的检测结果，并在投票集成层将多个
基学习器检测结果通过投票获得最终结果输出。
图 3 则是通过 GPMD 生成的最优集成模型，图中每一
层的函数及其作用将在 2.3 节详细阐述。该集成模型融合了
传统的恶意软件集成检测方法后两个阶段，将特征处理、设
计集成模型两个过程相连接，使输入每个基学习器的特征不
再是相同的组合，而是可以进一步提高基学习器准确性的最
佳特征组合，且不同基学习器最佳特征组合也不同。如图 3
最优集成模型所示，在最左边的分支上每个样本原始特征经
过 Encode 转换为三张 16*16 的灰度图像，之后 Weight_img
将三张灰度图像加权融合为一张图像。经过卷积池化操作最
终获得 64 维的高级特征向量，在特征融合阶段与局部特征
sec 拼接形成一个 74 维特征向量输入到 ERF 进行训练。在
第二棵子树中，每个样本经过特征学习层 HOG 函数获取图
像的梯度特征，之后和局部特征 sec 融合成 35 维高级特征
向量输入到基学习器进行训练。而第三棵子树输入基学习器的高级特征向量维数为 100，该特征向量由三种类型构成，
包括由 LBP 函数提取的 58 维纹理特征、sec 样本局部特征、
卷积池化层提取的 32 维特征向量。该模型可以清晰的看到
每个基学习器所使用的特征组合，以及这些特征组合如何产
生，因此比其他恶意软件检测方法具有更高的可解释性。特征图像化层采用两种编码方式，将恶意软件原始特征
his、byte、imp 转换为灰度图像，使模型对代码混淆具有一
定的适应能力。输入是标准化处理后的多个类型的恶意软件
特征，输出是灰度图像。主要使用两种图像化函数，一种是
直接编码 Encode 函数，将标准化处理后的原始特征与 255
相乘转换为 16*16 的灰度图像。另一种采用双字节编码
Byte_Encode 函数，首先将标准化后的原始特征中每一个特
征值转换为二进制，之后将小数点向右移动 16 位，每八位
转换为一个像素值。如某个标准化后的特征值为 0.023458，
经过双字节编码转换为像素值 6，1，经过双字节特征编码
转换为灰度图像，减少精度损失，原始特征扩大一倍变为此外，GPMD 通过输入属性扰动和算法参数扰动两种
方法，使进化生成的最优集成模型具有很高的多样性。如
在特征处理过程中，每层使用不同函数获取不同的高级特
征向量，之后这些特征向量作为基学习器的输入，训练出
不同的基学习器。在 GPMD 中将基学习器的参数设为叶子
节点，可以在进化学习过程中自动调整参数，实现算法参
数扰动。如图 3 中，中间及右边两棵子树虽然均使用
LightGBM 分类算法作为基学习器，但是两者所使用的算
法参数、算法所使用的特征向量均不相同，训练出基学习
器也会产生较大差别。
2.3 功能集
功能集是 GPMD 的关键组成部分之一，它构成了
GPMD中每个集成模型树的内部节点，根据每一层的作用，
在功能集中有六种不同类型的函数，每层函数如表 1 所示。
本节将从下到上介绍每一层的功能及其函数。
表 1 函数集
Tab. 1 Function set
功能层 函数
特征图像化 Encode、Byte_Encode
图像加权融合 Avg_img、Weight_img
特征学习
Cov1、MaxP、AvgP、Mix_Cat、Mix_Add、
LBP、HOG、SIFT
特征融合层 FeaCon2、FeaCon3、FeaCon4、FeaCon5
基学习器选择层 SVM、LR、RF、ERF、LightGBM
集成层 Combine3、Combine 516*32 的灰度图像，某个样本图像化结果如图 4 所示，其中
图 4(a1)(a2)(a3)采用 Encode 函数对 his、byte、imp 三个特征
图像化，图 4(b1)～（b3)采用 Byte_Encode 函数对 his、byte、
imp 三个特征图像化。
图像加权融合层主要功能是对输入的三张特征图像融合，
减少集成模型的计算量。输入为三张灰度图像 X、Y、Z，
输出为一张灰度图像。设计了两种融合的函数，一种是
Avg_img 认为每个类型特征重要性相同，融合公式为
Avg img X Y Z _ ( )/3 = + + 。另一种方法 Weight_img，考
虑到在恶意软件中，不同类型特征的重要性不同，该函数对
三 个 特 征 赋 予 不 同 的 权 重 进 行 融 合 。 融 合 公 式 为Weight img X Y Z _ ( *299 *587 *144 500)/1000 = + + + 。
将图 4 的样本灰度特征图融合结果如图 5 所示，其中 X 代表
byte、Y 代表 his、Z 代表 imp。通过图 4、图 5 对比发现，
融合后的灰度图像所含信息更为丰富，同时减小了模型计算量。
特征学习层可细分为卷积、池化及传统的图像处理算子，
用于提取图像中不同类型的特征。它们以图像作为输入，输
出是一维特征向量。卷积层函数为 Cov，在该函数中图像通
过与卷积核的矩阵运算，得到比像素值更高级的特征。后经
过多种池化层函数，如最大池化 MaxP、平均池化 AvgP、组
合池化 Mix_Cat、Mix_Add 提取卷积后图像特征，降低特征
信息冗余。传统的图像处理算子包括 LBP 函数、HOG 函数、
SIFT 函数。LBP 函数采用圆形 LPB 算子生成 LBP 图像，将
采样点设为 8，提取像素块与其邻居之间的关系生成一个 58
维特征。HOG 函数则是提取图像一定区域大小的直方图特
征并进行归一化，区域大小作为 GPMD 的叶子节点，并在
终端集中设置取值范围，具体描述在 2.4 节。
Fig. 5 Image weighted fusion example
SIFT函数则是从图像中检测关键点，并从中提取 128维
特征。该层中每个图像特征提取函数可以提取到不同数量的
特征，经过特征学习后的使得特征更加紧凑，能够抵抗噪声
干扰。
特征融合层的函数分为 FeaCon2、FeaCon3、FeaCon4、
FeaCon5 四种，可以分别将两个、三个、四个、五个向量融
合，形成一个新的特征向量，输入到基学习器中。该层函数
输入为经过特征学习层生成的特征、Sec 局部特征，输出为
一个一维特征向量。
在基学习器选择层，为了减少搜索空间，主要采用了支
持向量机(SVM)、随机森林(RandomForest，RF)、极端树
(ExtraTree，ERF)、逻辑回归(LR)和 LightGBM 五个在恶意
软件检测方面最常用的分类算法，并将每个分类算法的参数
设为 GPMD 的叶子节点，使其在进化过程中自动优化，这
些关键参数将在 2.4 节中详细介绍。
集成层层函数为 Combine 3 和 Combine 5，在集成学习
中常用的集成策略分为平均法和投票法两种，而恶意软件检
测属于分类任务，且 GPMD 生成集成模型既可能是同质集
成也可能异构集成，因此采用投票法对基学习器结果进行集
成更为合适。输入可以是单个基学习器的预测标签，也可以
是多个基学习器集成后的预测标签。输出是每个样本的预测
标签。
2.4 终端集
终端集表示GPMD 中个体即集成模型的输入，如表 2 所示。
表 2 终端集
Tab. 2 Terminal set
参数 类型 含义
his Array 字节统计特征
byte Array 字节熵特征
imp Array 函数调用特征
sec Array 区段特征
Label Array 样本标签
filter Array 卷积核权值，范围是[-0.2,0.2]
filter_size Int 卷积核大小，可选 3/5/7
r Float 圆形 LBP 算子半径，范围[1,3]
size Int 池化及求 HOG 特征平均值范围，范围[2,4]
C Int LR 和 SVM 的正则项参数为 10-c，范围[-5,-2]
lr Float LightGBM 分类算法的学习率，范围[0.05,0.1]
n Int
LightGBM 分类算法的迭代次数
范围[100,1000]，步长 50
tree_num Int
RF、ERF 分类算法的子树个数，
范围[100,1000],步长 50
max_depth Int
RF、ERF 分类算法的最大深度，
范围[10,100],步长 10
his、byte、imp、sec 表示从数据集中提取到的原始特征，
除 sec 外其他三个特征大小为 600000*256(训练集样本数*特
征向量维数)，sec 为 600000*10。Label 表示数据集样本标签，
0 表示良性样本、1 表示恶意样本。filter、filter_size、r、
size 是特征学习层函数的重要参数，filter 表示卷积核的权值。
filter_size 表示卷积核大小，常用大小为 3*3、5*5 及 7*7。r
为圆形 LBP 算子的半径，其范围为[1,3]。Size 取值范围[2,4]，
表示池化范围以及计算 HOG 算子平均特征值时的区域大小。
此外，基学习器的重要参数也被设计为 GPMD 的终端，包
括分类算法 SVM 和 LR 的正则化参数 10(-C)，C 的取值范围
是[-2,5]。LightGBM 分类算法的稳定性和准确性取决于学习
率(lr)和迭代次数(n)这两个重要参数，lr 常用的取值范围为
[0.05,0.1], n 的常用取值范围为[100,1000]。RF 和 ERF 中重
要参数是子树个数(tree_num)及最大深度(max_depth)，因此tree_num 及 max_depth 也 作 为 输 入 ， 它 们 范 围 分 别 是
[100,1000]、[10,100]，为了避免 GPMD 的搜索空间过大，
tree_num 在其范围内步长为 50 的增加或减少，max_depth 在
其范围内步长为 10 的增加或减少3 实验结果与对比分析
3.1 数据集
EMBER 数据集[19]是基于 PE 格式的恶意软件检测基准
数据集之一，该数据集包含 40 万个良性样本、40 万个恶意
样本、30 万未知样本。考虑到恶意软件原始文件公开会带
来各种安全问题，EMBER 的发布者并没有公开原始文件，
而是提供了可以反映原始文件的原有特性的一些特征及其标
签。数据集中每个样本保存为一个 JSON 对象，每个对象的
特征数据包含 sha256 哈希值、出现时间(appeared)、标签
(label)、通用文件信息(general)、头部信息(header)、导入函
数(imports)、导出函数(exports)、区段信息(section)、字节直
方图(histogram)、字节熵直方图(byteentropy)、字符串信息
(string)这些字段。其中标签 1 代表恶意软件、标签 0 代表良
性样本、标签-1 表示未知样本，研究者们可以从这些原始特
征中提取特征向量及样本标签。本文提取导入函数(imports)、
字节直方图(histogram)、字节熵直方图(byteentropy)、区段
信息(section)这四个字段信息转换为四个特征向量，作为
GPMD和最优集成模型的输入。在本实验中，剔除未知样本
(标签为-1)，剩余 80 万样本中，60 万个样本作为模型生成
和最优集成模型性能测试时训练集，20 万样本作为最优集
成模型性能测试的测试集。
3.2 实验环境及评价指标
本文的 实验环 境如下 ：硬 件环境 为 i9-10900XCPU
@3.70GHz，RAM 30.0GB；软件环境为 Linux 系统，python
3.8，deap 1.3.1，scikit-learn 0.24.2 以及其他工具包。为了充
分评估模型的性能，本文选用恶意代码检测领域的四个常用
评测标准，准确率(Accuracy)、召回率(Recall)、查准率
(Precision)、F1 值以及检测时间多方面对最优集成模型进行
评估。
3.3 GP 参数设置
由于 CPMD 中个体结构每一层功能函数及相关参数选
择较为灵活，为了获得表现更好的个体，因此种群大小设为
1000，生成尽可能多的集成模型。其余参数本文根据文献
[20]及经验设置 GPMD 的参数如表 3 所示。在 GPMD 中，
种群初始化后，每一代种群通过锦标赛选择用于在进化学习
过程中选择进行变异和交叉的父代个体，该过程利用基于
Python 中的分布式进化算法[21]实现。
表 3 GP 参数设置
Tab. 3 GP parameter settings
参数 值 参数 值
种群大小 1000 遗传代数 50
精英选择概率 0.01 交叉率 0.9
突变率 0.2 锦标赛选择个体 7
GPMD可以通过种群遗传迭代来提高集成分类器的性能，
遗传代数太小，种群进化不成熟，集成分类器性能达不到最
优；遗传代数太大，种群中已存在最优集成模型，继续进化
没有意义，只会增加时间开支和资源浪费。本文在实验中记
录了 GPMD 中遗传代数与每一代集成检测模型平均准确率
之间的关系如图 6，通过图 6 发现当迭代次数到达 50 时，平
均准确率趋于平稳，表明种群已经出现最佳解决方案即最优
集成模型。
图 6 遗传代数与集成检测模型平均准确率关系
Fig. 6 Relationship between generation and average accuracy of
integrated detection model
3.4 实验结果与分析
为了充分证明最优集成检测模型图 3 的实际效果，本文
对比的基准方法为 SVM、LR、RF、ERF、AdaBoost、
LightGBM、CNN、文献[10]的集成模型、文献[22]的集成模
型。其中，基准方法 SVM、LR、RF、ERF 、AdaBoost、
LightGBM 是基于机器学习包 scikit-learn 实现的，相关参数
则是此包中网格搜索 GridSeachCV 方法选择最优超参数组合，
以获得最好的模型表现，相关参数的范围与 GPMD 所使用
的范围一致。这些基准方法输入为标准化后的 his、byte、
imp、sec 四个原始特征。CNN 方法则是通过 Tensorflow 实
现，网络结构及参数参考文献[17]，其将原始特征转换为
28*28 的灰度图片，输入到 CNN 模型中。文献[10]的集成模
型输入为 28*28 的灰度图像全局纹理特征，基础分类参数及
集成策略与文献[10]一致。根据文献[22]中不同类型特征采
用不同类型的基学习器和集成策略，his、byte 属于非 PE 特
征，sec、imp 属于 PE 特征，依据文中基学习器表选择不同
的基学习器并采用 Stacking 集成策略，非 PE 特征将 SVM 作
为元学习器，PE 特征将 KNN 作为元学习器，最终将两者结
果依照文献[22]中权重投票策略获得最终预测结果。实验结
果与表 4 所示
表 4 不同分类算法检测效果对比
Tab. 4 Comparison of different classification algorithms
分类算法
评价指标
Accurary(%) Recall(%) Precision(%) F1-Score(%)
SVM 77.44 86.75 79.37 82.91
LR 73.48 72.63 73.93 73.27
RF 95.03 90.11 86.53 93.72
ERF 94.91 93.06 88.71 90.86
AdaBoost 86.7 84.27 88.57 86.37
LightGBM 95.86 96.38 93.63 95.04
CNN 97.8 97.03 98.41 97.61
文献[10] 96.81 95.38 94.15 94.78
文献[22] 96.99 94.45 90.04 92.19
本文模型 98.88 98.54 99.12 98.88
通过实验结果对比分析，发现本文模型无论是 Accuracy、
Recall、Precision 还是 F1-Score 都显著高于其他机器学习模
型。相比于 RF、ERF、AdaBoost、LightGBM 这些基于树的
单一集成学习模型，本文通过 GBMD 生成的最优集成检测
模型在 F1 值上分别高出 5.16%、8.02%、12.51%、10.48%和
3.84%。与其他恶意软件集成检测模型相比，本文提出的集成模型具有更好的检测效果。
除了考虑模型的分类性能外，本文对 GPMD 生成最优
集成模型和其他机器学习模型使用网格搜索参数调优的时间
进行对比分析，如图 7 所示，每个模型在相同的软硬件环境
下进行参数调优。
图 7 获得最优检测模型的时间对比
Fig. 7 Time comparison of optimal detection model
本文对上述不同分类算法获得的表现最好的模型的运行
时间进行分析比较(本文模型的运行时间是指模型训练完后，
在测试集上进行预测，单个样本所使用的时间)，具体结果
如图 8 所示。
图 8 不同模型检测时间对比
Fig. 8 Comparison of detection time of different models
图 7、图 8 对比发现， GPMD 生成最佳集成模型的时
间与常见的集成学习算法 RF、ERF、LightGBM 获得最优超
参数组合的时间接近，最优模型检测时间分别相差 0.0061s、
0.0017s、0.0098s，但是这三个模型检测准确性不如本文模
型。单个机器学习模型如 SVM、LR 参数调优和检测耗时较
短，但是检测准确率偏低。结合表 4 对比分析其他集成检测
模型，发现本文的模型在保证检测效果最好的情况下拥有较
短的检测时间，获得最优集成模型所耗费的时间也在可接受
范围内。
此外，为了进一步验证通过 GPMD 生成的最优集成模
型的有效性，本文获取最优集成模型中三棵子树的评价指标。
并将第二棵子树的基学习器换为 RF，其他参数即函数节点
不变，该集成模型记为模型 1，获取模型 1 的评价指标，实
验结果如表 5 所示。
最优集成检测模型中子树所使用的基学习器为 ERF、
LightGBM，各项指标均优于表 4 中 ERF、LightGBM 的检测
效果，表明经过 GPMD 进化生成的特征组合提高了分类算
法的检测准确率。而三棵子树通过投票函数提高了整个模型
的检测准确率，各项评价指标均高于模型 1，也进一步表明
GPMD在进化过程中可以找到较好的集成方案。综上所述，
GPMD在进化过程中会为每个基学习器选择不同的特征组合，
并找到较好的基学习器集成方案，使最终生成的最优集成模
型不仅具有高准确率，而且具备较高的多样性。
表 5 最优集成模型中子树检测效果对比
Tab. 5 Comparison of subtree detection effects in the best ensemble model
子树
评价指标
Accurary(%) Recall(%) Precision(%) F1-Score(%)
左边子树 95.91 94.06 92.71 93.41
中间子树 96.37 96.58 94.63 95.59
右边子树 96.63 97.11 95.53 96.34
模型 1 97.39 96.05 95.13 95.61
4 结束语
本文将遗传规划算法应用于恶意软件检测领域，提出了
一种基于遗传规划的恶意软件集成检测模型生成的方法，并
设计了一种集成模型结构用于表示GPMD中的个体。GPMD
方法将恶意软件检测的特征处理与构建集成模型两个过程融
合在一个 GPMD 个体中，可以从原始特征中获得最佳特征
组合，自动优化分类器中的参数，使集成模型中的基学习器
可以在进化过程中增加其多样性并保证准确性。之后将
GPMD生成的最优集成模型与多个模型性能对比实验分析，
结果表明，本文经过 GPMD 生成的最优集成模型比其他检
测模型有更好的性能。此外，进一步分析表明，针对恶意软
件检测，GPMD方法可以有效地生成高准确性、多样性和高
可解释性的集成模型。
由于目前恶意软件检测相关的数据集有限，未能充分体
现出本文方法所生成的最优模型在其他数据集上的可扩展性。
下一步将考虑收集更多的恶意软件数据集，通过多数据集融
合，采用多种集成策略，探究通用性更强的集成模型。此外，
未来将考虑将该方法用于恶意软件分类领域，为评估恶意软
件的危险性提供参考。
